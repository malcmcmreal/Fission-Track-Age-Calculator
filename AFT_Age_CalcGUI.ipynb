{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import subprocess\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gs\n",
    "import matplotlib.colors as mcol\n",
    "from matplotlib.ticker import LinearLocator\n",
    "from scipy.stats import gamma\n",
    "from datetime import date\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, FileUpload, Button, Layout, IntProgress, Checkbox, Button, HBox, VBox, Output, Box, Label\n",
    "from IPython.display import display, clear_output, Javascript, Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "#calls the CentralAge.py file (should be in the same folder as project)\n",
    "from CentralAge import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) DEFINE VARIABLES AND CHECK CONSTANTS\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885eeb5e87174f8887521c5593d2b9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Select(description='(R) Track Init:', index=1, options=(('7.5e-4 (FCT)', 0.00075…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d68ae5fe484f94891b033e143a5316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Default Values', style=ButtonStyle()),))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RAp_w = widgets.Select(\n",
    "    options=[(\"7.5e-4 (FCT)\",7.5E-4), (\"7.17e-4 (DUR)\",7.17E-4), (\"5.3e-4 (ZIR)\",5.3E-4), (\"5.3e-4 (MONZ)\",5.3E-4)],\n",
    "    value=7.17E-4,\n",
    "    rows=4,\n",
    "    description='(R) Track Init:',\n",
    "    disabled=False)\n",
    "\n",
    "qAp_w = widgets.FloatText(\n",
    "    value=0.93,\n",
    "    description='(q) Etch Fact:',\n",
    "    step=0.01,\n",
    "    disabled=False,)\n",
    "\n",
    "dAp_w = widgets.Select(\n",
    "    options=[(\"3.21 (Ap)\",3.21), (\"4.7 (Zr)\",4.7),(\"5.15 (Mz)\",5.15)],\n",
    "    value=3.21,\n",
    "    rows=3,\n",
    "    description='(d) Density:',\n",
    "    disabled=False)\n",
    "\n",
    "M238U_w = widgets.FloatText(\n",
    "    value=238.051,\n",
    "    description='M238U:',\n",
    "    step=0.01,\n",
    "    disabled=True)\n",
    "\n",
    "g_w = widgets.FloatText(\n",
    "    value=1.0,\n",
    "    description='g:',\n",
    "    step=0.01,\n",
    "    disabled=False)\n",
    "\n",
    "ld_w = widgets.FloatText(\n",
    "    value=1.55125E-10,\n",
    "    description='λd:',\n",
    "    step=0.01,\n",
    "    disabled=True)\n",
    "\n",
    "lf_w = widgets.FloatText(\n",
    "    value=8.52E-17,\n",
    "    description='λf:',\n",
    "    step=0.01,\n",
    "    disabled=True)\n",
    "\n",
    "No_w = widgets.FloatText(\n",
    "    value=6.0221409E+23,\n",
    "    description='No:',\n",
    "    step=0.01,\n",
    "    disabled=True)\n",
    "\n",
    "def Xi_f(RAp_w, qAp_w, dAp_w, M238U_w, g_w, ld_w, lf_w, No_w):\n",
    "    global Xi\n",
    "    global RAp\n",
    "    global qAp\n",
    "    global dAp\n",
    "    global M238U\n",
    "    global g\n",
    "    global ld\n",
    "    global lf\n",
    "    global No\n",
    "    Xi = M238U_w/(lf_w*No_w*dAp_w*RAp_w*qAp_w)\n",
    "    RAp = RAp_w\n",
    "    qAp = qAp_w\n",
    "    dAp = dAp_w\n",
    "    M238U = M238U_w\n",
    "    g = g_w\n",
    "    ld = ld_w\n",
    "    lf = lf_w\n",
    "    No = No_w\n",
    "    print ('Aggregate factor ξ:'\" {:.4e}  t cm^2\".format(Xi))\n",
    "    print ('Equivalent to Vermeesch (2017) & IsoplotR ζ:'\" {:.1f}  t μm^2\".format(Xi*2*1000000))\n",
    "\n",
    "def reset_values1(b):\n",
    "    \"\"\"Reset to inital values.\"\"\"\n",
    "    RAp_w.value = 7.17E-4\n",
    "    qAp_w.value = 0.93\n",
    "    dAp_w.value = 3.21\n",
    "\n",
    "reset_button1 = widgets.Button(description = \"Default Values\")\n",
    "reset_button1.on_click(reset_values1)\n",
    "\n",
    "print('1) DEFINE VARIABLES AND CHECK CONSTANTS')\n",
    "out1 = widgets.interactive_output(Xi_f, {'RAp_w': RAp_w, 'qAp_w': qAp_w, 'dAp_w': dAp_w, 'M238U_w': M238U_w,\n",
    "                                     'g_w': g_w,'ld_w': ld_w, 'lf_w': lf_w, 'No_w': No_w})\n",
    "display(widgets.HBox([widgets.VBox([RAp_w,qAp_w,dAp_w,out1]),\n",
    "                      widgets.VBox([M238U_w,g_w,ld_w,lf_w,No_w])]),\n",
    "       widgets.HBox([reset_button1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) OPTIONAL META DATA USED IN EXPORT TABLES\n",
      "** If left blank, will attempt to retrieve information from FastTracks file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6708c1612f0a4d0b83c0d6b1ac0a3de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(Text(value='', description='Sample ID**:', placeholder='Sample_01'), Text(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f7955b513b4d4dab17f41d73c2a82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Default Values', style=ButtonStyle()), Button(description='Clear Inputs', s…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_name_w = widgets.Text(\n",
    "    #value='Sample_01',\n",
    "    placeholder='Sample_01',\n",
    "    description='Sample ID**:',\n",
    "    disabled=False)\n",
    "\n",
    "igsn_w = widgets.Text(\n",
    "    #value='123456',\n",
    "    placeholder='IGSN0011',\n",
    "    description='IGSN**:',\n",
    "    disabled=False)\n",
    "\n",
    "analyst_w = widgets.Text(\n",
    "    value='Your Name',\n",
    "    placeholder='Your Name',\n",
    "    description='Analyst**:',\n",
    "    disabled=False)\n",
    "\n",
    "collector_w = widgets.Text(\n",
    "    placeholder='Your Name?',\n",
    "    description='Collector:',\n",
    "    disabled=False)\n",
    "\n",
    "rock_type_w = widgets.Text(\n",
    "    #value='Hello World',\n",
    "    placeholder='Granite',\n",
    "    description='Rock Type:',\n",
    "    disabled=False)\n",
    "\n",
    "country_w = widgets.Text(\n",
    "    placeholder='Australia',\n",
    "    description='Country:',\n",
    "    disabled=False)\n",
    "\n",
    "region_w = widgets.Textarea(\n",
    "    #value='Hello World',\n",
    "    placeholder='Snowy Mountains',\n",
    "    description='Region:',\n",
    "    disabled=False)\n",
    "\n",
    "latitude_w = widgets.FloatText(\n",
    "    value=-12.3456,\n",
    "    #placeholder=-12.3456,\n",
    "    step=None,\n",
    "    description='Lat. (wgs84):',\n",
    "    disabled=False)\n",
    "\n",
    "longitude_w = widgets.FloatText(\n",
    "    value=12.3456,\n",
    "    #placeholder=12.3456,\n",
    "    step=None,\n",
    "    description='Lon. (wgs84):',\n",
    "    disabled=False)\n",
    "\n",
    "elevation_w = widgets.IntText(\n",
    "    #value=np.nan,\n",
    "    placeholder=100,\n",
    "    description='elevation (m):',\n",
    "    disabled=False)\n",
    "\n",
    "    #These will likely remain constant\n",
    "\n",
    "mineral_w = widgets.Select(\n",
    "    options=[(\"Apatite\",\"Apatite\"), (\"Zircon\",\"Zircon\"), (\"Monazite\",\"Monazite\")],\n",
    "    value='Apatite',\n",
    "    rows=3,\n",
    "    #placeholder='Apatite',\n",
    "    description='Mineral:',\n",
    "    disabled=False)\n",
    "\n",
    "Ustandard_w = widgets.Text(\n",
    "    value='Nist612',\n",
    "    placeholder='Standard',\n",
    "    description='Pimary Std:',\n",
    "    disabled=False)\n",
    "\n",
    "Intstandard_w = widgets.Select(\n",
    "    options=[(\"Durango\",'Durango'),\n",
    "             (\"NIST612\",'Nist612'),\n",
    "             (\"NIST614\",'Nist614'),\n",
    "            (\"MudTank\",'MudTank'),\n",
    "            (\"Other\",'other')],\n",
    "    value='Durango',\n",
    "    rows=5,\n",
    "    description='2nd Std:',\n",
    "    disabled=False)\n",
    "\n",
    "spot_size_w = widgets.Text(\n",
    "    value='30 µm',\n",
    "    placeholder='30 µm',\n",
    "    description='Spot Size:',\n",
    "    disabled=False)\n",
    "\n",
    "lab_name_w = widgets.Textarea(\n",
    "    value='University of Melbourne Thermochronology',\n",
    "    placeholder='University of ..',\n",
    "    description='Lab Name:',\n",
    "    disabled=False)\n",
    "\n",
    "etchant_w = widgets.Text(\n",
    "    value='5M HNO3',\n",
    "    placeholder='5M HNO3',\n",
    "    description='Etchant:',\n",
    "    disabled=False)\n",
    "\n",
    "etchant_w = widgets.Select(\n",
    "    options=[(\"5M HNO3\",'5M HNO3'), (\"5.5M HNO3\",'5.5M HNO3'),(\"6M HCl\",'6M HCl')],\n",
    "    value='5M HNO3',\n",
    "    rows=3,\n",
    "    description='Etchant:',\n",
    "    disabled=False)\n",
    "\n",
    "etching_time_w = widgets.Text(\n",
    "    value='20s',\n",
    "    placeholder='20s',\n",
    "    description='Etch Time:',\n",
    "    disabled=False)\n",
    "\n",
    "etching_temp_w = widgets.Text(\n",
    "    value='20C',\n",
    "    placeholder='20C',\n",
    "    description='Etch Temp.:',\n",
    "    disabled=False)\n",
    "\n",
    "rmr0pref_w = widgets.Select(\n",
    "    options=[(\"Ketcham 2007\",'2007'), (\"Ketcham/Carlson 1999\",'1999')],\n",
    "    value='2007',\n",
    "    rows=2,\n",
    "    description='rmr0 model:',\n",
    "    disabled=False)\n",
    "\n",
    "eCLpref_w = widgets.Select(\n",
    "    options=[(\"Ketcham 2007\",'2007'), (\"Ketcham 1999\",'1999')],\n",
    "    value='2007',\n",
    "    rows=2,\n",
    "    description='eCl model:',\n",
    "    disabled=False)\n",
    "\n",
    "def meta_f(sample_name_w, igsn_w, analyst_w, collector_w, rock_type_w,\n",
    "           country_w, region_w, latitude_w, longitude_w, elevation_w,\n",
    "          mineral_w, Ustandard_w, Intstandard_w, spot_size_w, lab_name_w, etchant_w,\n",
    "          etching_time_w, etching_temp_w, rmr0pref_w, eCLpref_w):\n",
    "    global sample_name\n",
    "    global igsn\n",
    "    global analyst\n",
    "    global collector\n",
    "    global rock_type\n",
    "    global country\n",
    "    global region\n",
    "    global latitude\n",
    "    global longitude\n",
    "    global elevation\n",
    "    global mineral\n",
    "    global Ustandard\n",
    "    global Intstandard\n",
    "    global spot_size\n",
    "    global lab_name\n",
    "    global etchant\n",
    "    global etching_time\n",
    "    global etching_temp\n",
    "    global rmr0pref\n",
    "    global eCLpref\n",
    "    sample_name = sample_name_w\n",
    "    igsn = igsn_w\n",
    "    analyst = analyst_w\n",
    "    collector = collector_w\n",
    "    rock_type = rock_type_w\n",
    "    country = country_w\n",
    "    region = region_w\n",
    "    latitude = round(latitude_w,6)\n",
    "    longitude = round(longitude_w,6)\n",
    "    elevation = elevation_w\n",
    "    mineral = mineral_w\n",
    "    Ustandard = Ustandard_w\n",
    "    Intstandard = Intstandard_w\n",
    "    spot_size = spot_size_w\n",
    "    lab_name = lab_name_w\n",
    "    etchant = etchant_w\n",
    "    etching_time = etching_time_w\n",
    "    etching_temp = etching_temp_w\n",
    "    rmr0pref = rmr0pref_w\n",
    "    eCLpref = eCLpref_w\n",
    "    \n",
    "\n",
    "def reset_values2(b):\n",
    "    \"\"\"Clear to defined values.\"\"\"\n",
    "    sample_name_w.value = ''\n",
    "    igsn_w.value = ''\n",
    "    analyst_w.value = ''\n",
    "    collector_w.value = ''\n",
    "    rock_type_w.value = ''\n",
    "    country_w.value = ''\n",
    "    region_w.value = ''\n",
    "    latitude_w.value = np.nan\n",
    "    longitude_w.value = np.nan\n",
    "    elevation_w.value = 0\n",
    "    lab_name_w.value = ''\n",
    "\n",
    "reset_button2 = widgets.Button(description = \"Clear Inputs\")\n",
    "reset_button2.style.button_color = 'orange'\n",
    "reset_button2.on_click(reset_values2)\n",
    "\n",
    "def reset_values3(b):\n",
    "    \"\"\"Reset to defined values.\"\"\"\n",
    "    mineral_w.value = \"Apatite\"\n",
    "    Ustandard_w.value = 'Nist612'\n",
    "    Intstandard_w.value = 'Durango'\n",
    "    spot_size_w.value = '30 µm'\n",
    "    lab_name_w.value = 'University of Melbourne Thermochronology'\n",
    "    etchant_w.value = '5M HNO3'\n",
    "    etching_time_w.value = '20s'\n",
    "    etching_temp_w.value = '20C'\n",
    "    sample_name_w.value = ''\n",
    "    analyst_w.value = 'Your Name'\n",
    "    collector_w.value = ''\n",
    "    rock_type_w.value = ''\n",
    "    country_w.value = ''\n",
    "    region_w.value = ''\n",
    "    latitude_w.value = -12.3456\n",
    "    longitude_w.value = 12.3456\n",
    "    elevation_w.value = 0\n",
    "\n",
    "reset_button3 = widgets.Button(description = \"Default Values\")\n",
    "#reset_button3.style.button_color = 'gray'\n",
    "reset_button3.on_click(reset_values3)\n",
    "\n",
    "print(\"2) OPTIONAL META DATA USED IN EXPORT TABLES\")\n",
    "print(\"** If left blank, will attempt to retrieve information from FastTracks file\")\n",
    "out2 = widgets.interactive_output(meta_f, {'sample_name_w': sample_name_w,'igsn_w': igsn_w, 'analyst_w': analyst_w, 'collector_w': collector_w,\n",
    "                                           'rock_type_w': rock_type_w,'country_w': country_w,'region_w': region_w,\n",
    "                                           'latitude_w': latitude_w, 'longitude_w': longitude_w, 'elevation_w': elevation_w,\n",
    "                                          'mineral_w': mineral_w, 'Ustandard_w': Ustandard_w, 'Intstandard_w': Intstandard_w,\n",
    "                                           'spot_size_w': spot_size_w, 'lab_name_w': lab_name_w, 'etchant_w': etchant_w,\n",
    "                                           'etching_time_w': etching_time_w,'etching_temp_w': etching_temp_w,\n",
    "                                          'rmr0pref_w': rmr0pref_w,'eCLpref_w': eCLpref_w})\n",
    "\n",
    "display(widgets.HBox([widgets.VBox([sample_name_w,igsn_w,analyst_w, collector_w, rock_type_w,\n",
    "           country_w, region_w, latitude_w, longitude_w, elevation_w, Ustandard_w, Intstandard_w,]),\n",
    "                      \n",
    "              widgets.VBox([mineral_w, spot_size_w, lab_name_w, etchant_w,\n",
    "          etching_time_w, etching_temp_w, rmr0pref_w, eCLpref_w])]),\n",
    "        \n",
    "        widgets.HBox([reset_button3,reset_button2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3) INPUT DIRECTORY TO PATH WHERE FILES WILL BE SAVED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86f858884bf14e12a7944e69811173a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Text(value='/Users/USER/FOLDER/SAVE_HERE', description='Save To:', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('3) INPUT DIRECTORY TO PATH WHERE FILES WILL BE SAVED')\n",
    "files_save_to_w = widgets.Text(\n",
    "    value='/Users/USER/FOLDER/SAVE_HERE',\n",
    "    placeholder='/Users/USER/Desktop/AFT_Calc',\n",
    "    description='Save To:',\n",
    "    layout=Layout(width='80%', height='100%'),\n",
    "    disabled=False)\n",
    "\n",
    "def clear_folder(b):\n",
    "    files_save_to_w.value = \"\"\n",
    "    out_p.clear_output()\n",
    "clear_button = widgets.Button(description = \"Clear Path\")\n",
    "clear_button.style.button_color = 'orange'\n",
    "clear_button.on_click(clear_folder)\n",
    "\n",
    "\n",
    "display(widgets.VBox([widgets.HBox([files_save_to_w]),widgets.HBox([clear_button])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4) AUTO-RETRIEVE DATA FILES LOCATED IN PARENT/SUB FOLDER(s) by SAMPLED ID -OR- UPLOAD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2449fce4a947fcb57047c29c53e0e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='Path to Parent Folder w/ Data Folder(s):'), Text(value='/Users/USER/…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED>> (if auto-retrieving, make sure to ''store'')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3fb7c4a65cf42799a82c932105b6425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(button_style='primary', description='Test Folder Path', style=ButtonStyle()), Button(but…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeec3fae361d41ecbff91186d25d45aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63150d870cbd467eb57c21fb9c9138c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_paths_test = []\n",
    "ICPMS_paths_test = []\n",
    "lengths_paths_test = []\n",
    "counts_paths = []\n",
    "ICPMS_paths = []\n",
    "lengths_paths = []\n",
    "\n",
    "\n",
    "files_get_from_w = widgets.Text(\n",
    "    value='/Users/USER/FOLDER/DATA_FOLDER',\n",
    "    placeholder='/Users/USER/FOLDER/DATA_FOLDER Counts.csv & Lengths.csv & ICPMS.txt',\n",
    "    #description='Look In:',\n",
    "    layout=Layout(width='70%', height='100%'),\n",
    "    disabled=False)\n",
    "\n",
    "countskey_w = widgets.Text(\n",
    "    value='Counts',\n",
    "    placeholder='Counts',\n",
    "    layout=Layout(width='20%', height='100%'),\n",
    "    disabled=False)\n",
    "\n",
    "lengthskey_w = widgets.Text(\n",
    "    value='Lengths',\n",
    "    placeholder='Lengths',\n",
    "    layout=Layout(width='20%', height='100%'),\n",
    "    disabled=False)\n",
    "\n",
    "icpmskey_w = widgets.Text(\n",
    "    value='ICPMS',\n",
    "    placeholder='ICPMS',\n",
    "    layout=Layout(width='20%', height='100%'),\n",
    "    disabled=False)\n",
    "\n",
    "def test_retrieve(b_test): \n",
    "    global counts_paths_test\n",
    "    counts_paths_test = []\n",
    "    for root, dirs, files in os.walk(files_get_from_w.value):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root,f)\n",
    "            if countskey_w.value in fullpath and sample_name in fullpath and \".csv\" in fullpath:\n",
    "                counts_paths_test.append(fullpath)\n",
    "                if len(counts_paths_test) >2:\n",
    "                    break\n",
    "    with out_t:\n",
    "        if len(counts_paths_test) == 0:\n",
    "            print(\"!!! Couldn't Find Minimum Data Files Using PATH\")\n",
    "        elif len(counts_paths_test) >2:\n",
    "            print(\"!!! Found multiple non-unique options using sample ID, check ID field (STEP 2)\")\n",
    "        else:\n",
    "            print (\"Track Counts File: {}\".format(counts_paths_test[0].split(\"/\")[-1]))\n",
    "    if counts_paths_test ==[]:\n",
    "        with out_t:\n",
    "            print('Searching in path.. {0}\\nNo File Matching Counts/{1}.csv found in path'.format(files_get_from_w.value,sample_name))\n",
    "            \n",
    "    global ICPMS_paths_test\n",
    "    ICPMS_paths_test = []\n",
    "    for root, dirs, files in os.walk(files_get_from_w.value):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root,f)\n",
    "            if icpmskey_w.value in fullpath and sample_name in fullpath and \".txt\" in fullpath:\n",
    "                ICPMS_paths_test.append(fullpath)\n",
    "                if len(counts_paths_test) >1:\n",
    "                    break\n",
    "                else:\n",
    "                    with out_t:\n",
    "                        print (\"ICPMS File: {}\".format(ICPMS_paths_test[0].split(\"/\")[-1]))\n",
    "    if ICPMS_paths_test ==[]:\n",
    "        with out_t:\n",
    "            print('No File Matching ICPMS/{0}.txt found in path'.format(sample_name))\n",
    "    \n",
    "                \n",
    "    global lengths_paths_test\n",
    "    lengths_paths_test = []\n",
    "    for root, dirs, files in os.walk(files_get_from_w.value):\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(root,f)\n",
    "            if lengthskey_w.value in fullpath and sample_name in fullpath and \".csv\" in fullpath:\n",
    "                lengths_paths_test.append(fullpath)\n",
    "                if len(counts_paths_test) >1:\n",
    "                    break\n",
    "                else:\n",
    "                    with out_t:\n",
    "                        print (\"Lengths File: {}\".format(lengths_paths_test[0].split(\"/\")[-1]))\n",
    "    if lengths_paths_test ==[]:\n",
    "        with out_t:\n",
    "            print('No File Matching Lengths/{0}.csv found in path'.format(sample_name))\n",
    "\n",
    "    if ICPMS_paths_test and counts_paths_test != [] and len(counts_paths_test) ==1:\n",
    "        with out_t:\n",
    "            print ('>>Required Files Found, if correct \"Store Files\" and continue')\n",
    "            \n",
    "def retrieve(b_ret): \n",
    "    global counts_paths\n",
    "    global ICPMS_paths\n",
    "    global lengths_paths\n",
    "    if counts_paths_test != []:\n",
    "        counts_paths = counts_paths_test[0]\n",
    "    else:\n",
    "        counts_paths = []\n",
    "    if ICPMS_paths_test != []:\n",
    "        ICPMS_paths = ICPMS_paths_test[0]\n",
    "    else:\n",
    "        ICPMS_paths = []\n",
    "    if lengths_paths_test != []:\n",
    "        lengths_paths = lengths_paths_test[0]\n",
    "    else:\n",
    "        lengths_paths = []\n",
    "        \n",
    "    with out_r:\n",
    "        if counts_paths != []:\n",
    "            print (\"Track Counts File (stored): {}\".format(counts_paths.split(\"/\")[-1]))\n",
    "        else:\n",
    "            print (\"No Counts File Found, Try testing the path first.\\n   .csv files should be in PATH/Counts/Sample_01.csv\")\n",
    "    with out_r:\n",
    "        if ICPMS_paths != []:\n",
    "            print (\"ICPMS File (stored): {}\".format(ICPMS_paths.split(\"/\")[-1]))\n",
    "        else:\n",
    "            print (\"No ICPMS File Found, Try testing the path first\\n    .txt files should be in PATH/ICPMS/Sample_01.csv\")\n",
    "    with out_r:\n",
    "        if lengths_paths != []:\n",
    "            print (\"Lengths File (stored): {}\".format(lengths_paths.split(\"/\")[-1]))\n",
    "        else:\n",
    "            print (\"No Lengths File Found, is that correct?\")\n",
    "    with out_r:\n",
    "        if ICPMS_paths_test and counts_paths_test != []:\n",
    "            print ('>>Looks Good! Commit and Continue')\n",
    "        \n",
    "test_ret_button = widgets.Button(description = \"Test Folder Path\", button_style='primary')\n",
    "test_ret_button.on_click(test_retrieve)\n",
    "\n",
    "ret_button = widgets.Button(description = \"Store Found Files\", button_style='primary')\n",
    "ret_button.on_click(retrieve)\n",
    "\n",
    "                    \n",
    "out_t = Output()\n",
    "out_r = Output()\n",
    "\n",
    "def clear_retrieve(b):\n",
    "    files_get_from_w.value = \"\"\n",
    "clear_button2 = widgets.Button(description = \"Clear Path\", layout=Layout(width='20%', height='100%'))\n",
    "clear_button2.style.button_color = 'orange'\n",
    "clear_button2.on_click(clear_retrieve)\n",
    "\n",
    "\n",
    "searchitems_1 = [Label('Path to Parent Folder w/ Data Folder(s):'),files_get_from_w]\n",
    "searchitems_2 = [clear_button2]\n",
    "searchitems_3 = [Label('Folder or Data File Names Contain (case-sensitive):'),countskey_w, lengthskey_w,icpmskey_w]\n",
    "\n",
    "\n",
    "search_layout = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='90%',\n",
    "                    height='100%')\n",
    "\n",
    "search_layout2 = Layout(display='flex-grow',\n",
    "                    flex_flow='row',\n",
    "                    align_items='center',\n",
    "                    width='80%')\n",
    "\n",
    "search_layout3 = Layout(display='flex',\n",
    "                    flex_flow='row',\n",
    "                    align_items='stretch',\n",
    "                    width='90%')\n",
    "\n",
    "searchbox_1 = Box(children=searchitems_1, layout=search_layout)\n",
    "searchbox_2 = Box(children=searchitems_2, layout=search_layout2)\n",
    "searchbox_3 = Box(children=searchitems_3, layout=search_layout3)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "print ('4) AUTO-RETRIEVE DATA FILES LOCATED IN PARENT/SUB FOLDER(s) by SAMPLED ID -OR- UPLOAD')\n",
    "display(VBox([searchbox_1,searchbox_2,searchbox_3]))\n",
    "\n",
    "print(\"REQUIRED>> (if auto-retrieving, make sure to ''store'')\")\n",
    "display(widgets.HBox([test_ret_button,ret_button]))\n",
    "display(out_t,out_r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~Option 2~~\n",
      "4.1) MANUALLY UPLOAD DATA FILES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85fa5fd35934b6589d485fbc7ea1a28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FileUpload(value={}, accept='.csv', description='Counts (csv)*'), Output())), VB…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_file_w = FileUpload(accept='.csv',\n",
    "                      description='Counts (csv)*',\n",
    "                      multiple=False)\n",
    "icpms_file_w = FileUpload(accept='.txt',\n",
    "                      description='ICPMS (txt)*',\n",
    "                      multiple=False)\n",
    "lengths_file_w = FileUpload(accept='.csv',\n",
    "                      description='Lengths (csv)',\n",
    "                      multiple=False)\n",
    "\n",
    "def upload_c(counts_file_w):\n",
    "    if counts_file_w != {}:\n",
    "        print (next(iter(counts_file_w)))\n",
    "def upload_i(icpms_file_w):\n",
    "    if icpms_file_w != {}:\n",
    "        print (next(iter(icpms_file_w)))\n",
    "def upload_l(lengths_file_w):\n",
    "    if lengths_file_w != {}:\n",
    "        print (next(iter(lengths_file_w)))\n",
    "\n",
    "out_counts = widgets.interactive_output(upload_c, {'counts_file_w': counts_file_w})  \n",
    "out_icpms = widgets.interactive_output(upload_i, {'icpms_file_w': icpms_file_w}) \n",
    "out_lengths = widgets.interactive_output(upload_l, {'lengths_file_w': lengths_file_w}) \n",
    "    \n",
    "\n",
    "print(\"~~Option 2~~\")\n",
    "print(\"4.1) MANUALLY UPLOAD DATA FILES\")\n",
    "display(widgets.HBox([widgets.VBox([counts_file_w,out_counts]),\n",
    "              widgets.VBox([icpms_file_w,out_icpms]),\n",
    "             widgets.VBox([lengths_file_w,out_lengths])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5) READ THE UPLOADED FILES & CONTINUE  -or- RESTART\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c818b3982a4e22a718a46096ae3623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='success', description='Commit Files & Continue', layout=Layout(width='80%'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def clear_files(b):\n",
    "    out_t.clear_output()\n",
    "    out_r.clear_output()\n",
    "    global counts_paths_test\n",
    "    global ICPMS_paths_test\n",
    "    global lengths_paths_test\n",
    "    global counts_paths\n",
    "    global ICPMS_paths\n",
    "    global lengths_paths\n",
    "    counts_paths_test = []\n",
    "    ICPMS_paths_test = []\n",
    "    lengths_paths_test = []\n",
    "    counts_paths = []\n",
    "    ICPMS_paths = []\n",
    "    lengths_paths = []\n",
    "    out_counts.clear_output()\n",
    "    out_icpms.clear_output()\n",
    "    out_lengths.clear_output()\n",
    "    display(Javascript('IPython.notebook.execute_cell()'))\n",
    "    display(Javascript('IPython.notebook.execute_cells_below()'))\n",
    "    \n",
    "clear_button3 = widgets.Button(description = \"Clear Saved Data Files (reset to begin new sample)\",\n",
    "                               layout=Layout(width='80%'), button_style='danger')\n",
    "clear_button3.on_click(clear_files)\n",
    "\n",
    "\n",
    "out_p = Output()\n",
    "@out_p.capture(clear_output=True)\n",
    "def store_files(b):\n",
    "    global save_to\n",
    "    if files_save_to_w.value == '':\n",
    "        print(\"!! No place to save files, input working directory (STEP 3) !!\")\n",
    "    elif os.access(files_save_to_w.value, os.W_OK) == False:\n",
    "        print(\"!! Cannot continue, path to save (STEP 3) is either incorrect format or read-only !!\")\n",
    "    else:\n",
    "        save_to = '{0}/FTAge_Calc/{1}'.format(files_save_to_w.value,sample_name)\n",
    "        display(Javascript('IPython.notebook.execute_cells([9,10,11,12])'))\n",
    "        with out_p:\n",
    "            print('Files save to:',save_to)\n",
    "        if not os.path.exists(save_to): os.makedirs(save_to)  \n",
    "\n",
    "\n",
    "\n",
    "store_button = widgets.Button(description = \"Commit Files & Continue\",\n",
    "                              layout=Layout(width='80%'),button_style='success')\n",
    "store_button.on_click(store_files)\n",
    "\n",
    "\n",
    "print(\"5) READ THE UPLOADED FILES & CONTINUE  -or- RESTART\")\n",
    "display(widgets.VBox([store_button,clear_button3,out_p]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necessry blank cell?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Counts file found, variables assigned :)\n",
      "Software: FastTracks: v3.2.15\n",
      "Date Measured: 2022-05-18 15:13:26\n",
      "\n",
      "Sample: 17SB-46A\n",
      "No. Grains: 35\n",
      "_________________\n",
      ">>ICPMS file found, variables assigned :)\n",
      "First Unknown: Output_1_1\n",
      "No. of Unknowns: 35\n",
      "_________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 5: expected 3 fields, saw 7\\nSkipping line 6: expected 3 fields, saw 7\\nSkipping line 7: expected 3 fields, saw 7\\nSkipping line 8: expected 3 fields, saw 7\\nSkipping line 9: expected 3 fields, saw 7\\nSkipping line 10: expected 3 fields, saw 7\\nSkipping line 11: expected 3 fields, saw 7\\nSkipping line 12: expected 3 fields, saw 7\\nSkipping line 13: expected 3 fields, saw 7\\nSkipping line 14: expected 3 fields, saw 7\\nSkipping line 15: expected 3 fields, saw 7\\nSkipping line 16: expected 3 fields, saw 7\\nSkipping line 17: expected 3 fields, saw 7\\nSkipping line 18: expected 3 fields, saw 7\\nSkipping line 19: expected 3 fields, saw 7\\nSkipping line 20: expected 3 fields, saw 7\\nSkipping line 21: expected 3 fields, saw 7\\nSkipping line 22: expected 3 fields, saw 7\\nSkipping line 23: expected 3 fields, saw 7\\nSkipping line 24: expected 3 fields, saw 7\\nSkipping line 25: expected 3 fields, saw 7\\nSkipping line 26: expected 3 fields, saw 7\\nSkipping line 27: expected 3 fields, saw 7\\nSkipping line 28: expected 3 fields, saw 7\\nSkipping line 29: expected 3 fields, saw 7\\nSkipping line 30: expected 3 fields, saw 7\\nSkipping line 31: expected 3 fields, saw 7\\nSkipping line 32: expected 3 fields, saw 7\\nSkipping line 33: expected 3 fields, saw 7\\nSkipping line 34: expected 3 fields, saw 7\\nSkipping line 35: expected 3 fields, saw 7\\nSkipping line 36: expected 3 fields, saw 7\\nSkipping line 37: expected 3 fields, saw 7\\nSkipping line 38: expected 3 fields, saw 7\\nSkipping line 39: expected 3 fields, saw 7\\nSkipping line 40: expected 3 fields, saw 7\\n'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'True Length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'True Length'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-fe3e9d928d1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlengths_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m'--'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mtrue_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"True Length\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mmtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mmtl_sd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_length\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'True Length'"
     ]
    }
   ],
   "source": [
    "##Read Counts File##\n",
    "if counts_file_w.value == {} and counts_paths == [] and icpms_file_w.value == {} and ICPMS_paths == []:\n",
    "    print (\">> No Files, (Hit ~Commit~ button above to refresh)\")\n",
    "    \n",
    "else:\n",
    "    \n",
    "    if counts_file_w.value != {}:\n",
    "        counts_content = counts_file_w.value[next(iter(counts_file_w.value))]['content']\n",
    "        counts_data = pd.read_csv(io.BytesIO(counts_content), skiprows=4, error_bad_lines=False)\n",
    "        if counts_data.iat[0,0] != \"Grain01\":\n",
    "            counts_data = pd.read_csv(io.BytesIO(counts_content), skiprows=5, error_bad_lines=False)\n",
    "            #AUTO-generate some meta-data from the counts file header\n",
    "        cd_headeronly = pd.read_csv(io.BytesIO(counts_content), error_bad_lines=False, header=None)\n",
    "        \n",
    "    elif counts_file_w.value == {} and counts_paths != []:\n",
    "        counts_data = pd.read_csv(counts_paths, skiprows=4, error_bad_lines=False)  \n",
    "        if counts_data.iat[0,0] != \"Grain01\":\n",
    "            counts_data = pd.read_csv(counts_paths, skiprows=5, error_bad_lines=False)\n",
    "            #AUTO-generate some meta-data from the counts file header\n",
    "        cd_headeronly = pd.read_csv(counts_paths, error_bad_lines=False, header=None)\n",
    "    else:\n",
    "        counts_data = None\n",
    "        print('>>>>>No Counts File Found!\\nThis is required to continue!\\n_________________')\n",
    "        \n",
    "    if counts_data is not None:\n",
    "        sample_FT = cd_headeronly[0][0] #Uses this value only if Sample Name left blank at start\n",
    "        igsn_FT = cd_headeronly[1][2] #Uses this value only if IGSN left blank at start\n",
    "        analyst_FT = cd_headeronly[1][3] #Uses this value only if Analyst left blank at start\n",
    "        software = cd_headeronly[0][1]\n",
    "        if cd_headeronly[0][2] == \"Pixel Calibration X:\":\n",
    "            igsn_FT = '--'\n",
    "        if cd_headeronly[0][3] == \"Pixel Calibration Y:\":\n",
    "            analyst_FT = '--'\n",
    "            #px and py no longer included in latest FastTracks\n",
    "        #px = pd.to_numeric(cd_headeronly[1][2])\n",
    "        #py = pd.to_numeric(cd_headeronly[1][3])\n",
    "        date_meas = pd.to_datetime(cd_headeronly[2][0], infer_datetime_format=True)\n",
    "        print(\">>Counts file found, variables assigned :)\\nSoftware: {0}\\nDate Measured: {1}\\n\\nSample: {2}\\nNo. Grains: {3}\\n_________________\".format(software,date_meas,sample_FT,counts_data['Grain/Mica'].count()))\n",
    "        #counts_data.head()\n",
    "\n",
    "\n",
    "        ##Read ICPMS File##\n",
    "        if icpms_file_w.value != {}:\n",
    "            icpms_content = icpms_file_w.value[next(iter(icpms_file_w.value))]['content']\n",
    "                #Selects only the columns we need\n",
    "            icpms_data = pd.read_csv(io.BytesIO(icpms_content),delimiter=\"\\t\",\n",
    "                usecols=[\"Unnamed: 0\", \"U_ppm_m238\", \"U_ppm_m238_Int2SE\", \"Time\",\n",
    "                         \"Ca43_CPS\", \"Ca43_CPS_Int2SE\", \"Th_ppm_m232\", \"Th_ppm_m232_Int2SE\"],)\n",
    "        elif icpms_file_w.value == {} and ICPMS_paths != []:\n",
    "                #Selects only the columns we need\n",
    "            icpms_data = pd.read_csv(ICPMS_paths,delimiter=\"\\t\",\n",
    "                usecols=[\"Unnamed: 0\", \"U_ppm_m238\", \"U_ppm_m238_Int2SE\", \"Time\",\n",
    "                         \"Ca43_CPS\", \"Ca43_CPS_Int2SE\", \"Th_ppm_m232\", \"Th_ppm_m232_Int2SE\"],)\n",
    "        else:\n",
    "            icpms_data = None\n",
    "            print('No ICPMS File Found!\\nThis is required!\\n_________________')\n",
    "\n",
    "        if icpms_data is not None:\n",
    "                #Renames the unnamed column at column 0\n",
    "            icpms_data.rename( columns={'Unnamed: 0':'point_name'}, inplace=True )\n",
    "                # need to convert certain columns to floats instead of string for plotting, also fill nan with 0\n",
    "            cols_numeric = [\"U_ppm_m238\", \"U_ppm_m238_Int2SE\", \"Ca43_CPS\", \"Ca43_CPS_Int2SE\",\n",
    "                            \"Th_ppm_m232\", \"Th_ppm_m232_Int2SE\"]\n",
    "            icpms_data[cols_numeric] = icpms_data[cols_numeric].apply(pd.to_numeric, errors='coerce', axis=1).fillna(0)\n",
    "            ####DEFINE THE STANDARDS USED BASED ON POINT NAMES####\n",
    "            #Information for standards used, you might need to add more if you've used other ones\n",
    "            std_dur = icpms_data[icpms_data['point_name'].str.contains('Dur', na=False, case=False)]\n",
    "            std_612 = icpms_data[icpms_data['point_name'].str.contains('612', na=False, case=False)]\n",
    "            std_614 = icpms_data[icpms_data['point_name'].str.contains('614', na=False, case=False)]\n",
    "            std_mt = icpms_data[icpms_data['point_name'].str.contains('Mud', na=False, case=False)]\n",
    "            output = icpms_data[icpms_data['point_name'].str.contains('Output', na=False, case=False)]\n",
    "            #resets the index row number for each standards data frame\n",
    "            std_dur.reset_index(drop=True, inplace=True)\n",
    "            std_612.reset_index(drop=True, inplace=True)\n",
    "            std_614.reset_index(drop=True, inplace=True)\n",
    "            std_mt.reset_index(drop=True, inplace=True)\n",
    "            output.reset_index(drop=True, inplace=True)\n",
    "                #combines the counts data and icpms data at the correct location to align\n",
    "            age_df = pd.concat([counts_data, output], axis=1)\n",
    "                #replaces the word \"Grain\" before each grain to make it easier to handle later\n",
    "            age_df['Grain/Mica'].replace(regex=True,inplace=True,to_replace='Grain',value='')\n",
    "                #see the data header if you want> (remove .head() to see full data)\n",
    "            #age_df\n",
    "            print(\">>ICPMS file found, variables assigned :)\\nFirst Unknown: {0}\\nNo. of Unknowns: {1}\\n_________________\".format(output['point_name'][0],output['point_name'].count()))\n",
    "\n",
    "\n",
    "        ##Read Lengths File##\n",
    "        if lengths_file_w.value != {}:\n",
    "            lengths_content = lengths_file_w.value[next(iter(lengths_file_w.value))]['content']\n",
    "            lengths_data = pd.read_csv(io.BytesIO(lengths_content), skiprows=4)\n",
    "        elif lengths_file_w.value == {} and lengths_paths !=[]:\n",
    "            lengths_data = pd.read_csv(lengths_paths, skiprows=4)   \n",
    "        else:\n",
    "            print(\">>No lengths file found\\n_________________\")\n",
    "            lengths_content = '--'\n",
    "            lengths_data = '--'\n",
    "            true_length = '--'\n",
    "            mtl = '--'\n",
    "            mtl_sd = '--'\n",
    "            l_no = '--'\n",
    "            mtl_var = '--'\n",
    "            Dpar_lengths = '--'\n",
    "            Dpar_lengths_mean = '--'\n",
    "            rmr0D_lengths = '--'\n",
    "            rmr0D_lengths_mean = '--'\n",
    "            rmr0D_lengths_sdm = '--'\n",
    "\n",
    "        if lengths_data is not '--':\n",
    "            true_length = lengths_data[\"True Length\"]\n",
    "            mtl = round(true_length.mean(),2)\n",
    "            mtl_sd = round(true_length.std(),2)\n",
    "            l_no = true_length.count()\n",
    "            mtl_var = round(mtl_sd/np.sqrt(l_no),2)\n",
    "            Dpar_lengths = round(lengths_data[\"Average DPar(µmm)\"],2)\n",
    "            Dpar_lengths_mean = round(Dpar_lengths.mean(),2)\n",
    "            if etchant == '5M HNO3'and rmr0pref == '2007':\n",
    "                rmr0D_lengths = round(0.84*((4.58-(0.9231*Dpar_lengths+0.2515))/2.98)**(0.21),3)\n",
    "            elif etchant == '5M HNO3'and rmr0pref == '1999':\n",
    "                rmr0D_lengths = round(1-np.exp(0.647*((0.9231*Dpar_lengths+0.2515)-1.75)-1.834),3)\n",
    "            elif etchant == '5.5M HNO3' and rmr0pref == '2007':\n",
    "                rmr0D_lengths = round(0.84*((4.58-(Dpar_lengths))/2.98)**(0.21),3)\n",
    "            elif etchant == '5.5M HNO3'and rmr0pref == '1999':\n",
    "                rmr0D_lengths = round(1-np.exp(0.647*(Dpar_lengths-1.75)-1.834),3)\n",
    "            rmr0D_lengths_mean = round(rmr0D_lengths.mean(),3)\n",
    "            rmr0D_lengths_sdm = round(rmr0D_lengths.std(),3)\n",
    "            print(\">>Lengths file found, variables assigned :)\\nMTL: {0:.2f}±{1:.1f}\\nNo. Lengths: {2}\".format(mtl,mtl_sd,l_no))\n",
    "\n",
    "\n",
    "        if counts_file_w.value != {} or counts_paths != []:\n",
    "            ####PLOT SOME FIGURES FROM THE ICPMS DATA####\n",
    "\n",
    "            #define the accepted values for standards to use in plots\n",
    "            dur_value=12.2\n",
    "            dur_err=0.04\n",
    "            mt_value=3\n",
    "            mt_err=0.02\n",
    "            nist612_value=37.38\n",
    "            nist612_err=0.08\n",
    "            nist614_value=0.823\n",
    "            nist614_err=0.002\n",
    "            if Intstandard == 'other':\n",
    "                mean_intstd = '--'\n",
    "                meanerr_intstd = '--'\n",
    "\n",
    "            if len(std_dur['point_name']) != 0:\n",
    "                #####DURNAGO\n",
    "                #convert spot time to seconds\n",
    "                df_time_dur = pd.to_datetime(std_dur[\"Time\"])\n",
    "                x_dur = ((df_time_dur.dt.hour*60+df_time_dur.dt.minute)*60 + df_time_dur.dt.second)*10**(-4)\n",
    "                #find and define the Uppm\n",
    "                y_dur = std_dur[\"U_ppm_m238\"]\n",
    "                y_edur = std_dur[\"U_ppm_m238_Int2SE\"]/2\n",
    "                #define the mean line of the Uppm±SD\n",
    "                y_mdur = [np.mean(y_dur)]*len(x_dur)\n",
    "                y_medur = [np.mean(y_edur)]*len(x_dur)\n",
    "                \n",
    "                if Intstandard == 'Durango':\n",
    "                    mean_intstd =round(y_mdur[0], 1)\n",
    "                    meanerr_intstd = round(y_medur[0], 1)\n",
    "\n",
    "                \n",
    "            if len(std_mt['point_name']) != 0:\n",
    "                #####MUD_TANK\n",
    "                #convert spot time to seconds\n",
    "                df_time_mt = pd.to_datetime(std_mt[\"Time\"])\n",
    "                x_mt = ((df_time_mt.dt.hour*60+df_time_mt.dt.minute)*60 + df_time_mt.dt.second)*10**(-4)\n",
    "                #find and define the Uppm\n",
    "                y_mt = std_mt[\"U_ppm_m238\"]\n",
    "                y_emt = std_mt[\"U_ppm_m238_Int2SE\"]/2\n",
    "                #define the mean line of the Uppm±SD\n",
    "                y_mmt = [np.mean(y_mt)]*len(x_mt)\n",
    "                y_memt = [np.mean(y_emt)]*len(x_mt)\n",
    "                \n",
    "                if Intstandard == 'MudTank':\n",
    "                    mean_intstd =round(y_mmt[0], 1)\n",
    "                    meanerr_intstd = round(y_memt[0], 1)\n",
    "\n",
    "            ######OUTPUT(SAMPLES)\n",
    "            #convert spot time to seconds\n",
    "            df_time_output = pd.to_datetime(output[\"Time\"])\n",
    "            x_output = ((df_time_output.dt.hour*60+df_time_output.dt.minute)*60 + df_time_output.dt.second)*10**(-4)\n",
    "            #find and define the Uppm\n",
    "            y_output = output[\"U_ppm_m238\"]\n",
    "            y_eoutput = output[\"U_ppm_m238_Int2SE\"]\n",
    "            #define the mean line of the Uppm±SD\n",
    "            y_moutput = [np.mean(y_output)]*len(x_output)\n",
    "            y_meoutput = [np.mean(y_eoutput)]*len(x_output)\n",
    "\n",
    "            if len(std_612['point_name']) != 0:\n",
    "                #####NIST612\n",
    "                #convert spot time to seconds\n",
    "                df_time_nist612 = pd.to_datetime(std_612[\"Time\"])\n",
    "                x_nist612 = ((df_time_nist612.dt.hour*60+df_time_nist612.dt.minute)*60 + df_time_nist612.dt.second)*10**(-4)\n",
    "                #find and define the Uppm\n",
    "                y_nist612 = std_612[\"U_ppm_m238\"]\n",
    "                y_enist612 = std_612[\"U_ppm_m238_Int2SE\"]/2\n",
    "                #define the mean line of the Uppm±SD\n",
    "                y_mnist612 = [np.mean(y_nist612)]*len(x_nist612)\n",
    "                y_menist612 = [np.mean(y_enist612)]*len(x_nist612)\n",
    "                \n",
    "                if Intstandard == 'Nist612':\n",
    "                    mean_intstd =round(y_mnist612[0], 1)\n",
    "                    meanerr_intstd = round(y_menist612[0], 1)\n",
    "\n",
    "            if len(std_614['point_name']) != 0:\n",
    "                    #####NIST614\n",
    "                    #convert spot time to seconds\n",
    "                df_time_nist614 = pd.to_datetime(std_614[\"Time\"])\n",
    "                x_nist614 = ((df_time_nist614.dt.hour*60+df_time_nist614.dt.minute)*60 + df_time_nist614.dt.second)*10**(-4)\n",
    "                    #find and define the Uppm\n",
    "                y_nist614 = std_614[\"U_ppm_m238\"]\n",
    "                y_enist614 = std_614[\"U_ppm_m238_Int2SE\"]/2\n",
    "                    #define the mean line of the Uppm±SD\n",
    "                y_mnist614 = [np.mean(y_nist614)]*len(x_nist614)\n",
    "                y_menist614 = [np.mean(y_enist614)]*len(x_nist614)\n",
    "                \n",
    "                if Intstandard == 'Nist614':\n",
    "                    mean_intstd =round(y_mnist614[0], 1)\n",
    "                    meanerr_intstd = round(y_menist614[0], 1)\n",
    "\n",
    "\n",
    "            #####FIGURES######\n",
    "            #setup the figure (fig size is in inches)\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(9,9))\n",
    "\n",
    "            if len(std_614['point_name']) == 0:\n",
    "                    ####PLOT NIST612 if NIST614 was not shot\n",
    "                    #create a color span on plot representing the accepted value for the standard\n",
    "                axs[0,1].axhspan(nist612_value-nist612_err, nist612_value+nist612_err, alpha=0.1, color='cornflowerblue')\n",
    "                    #plot the measured mean Uppm line in ref material\n",
    "                axs[0,1].plot(x_nist612,y_mnist612, label='Mean', linestyle='-', color='#8B0000', alpha=0.5)\n",
    "                axs[0,1].text(np.mean(x_nist612), np.mean(y_mnist612) + np.mean(y_mnist612)*0.01,'mean: {0:.2f}'\" \"u'\\xb1'\" \"'{1:.2f}'\" \"'ppm' .format(round(y_mnist612[0], 2),round(y_menist612[0], 2)),fontsize=11, ha='center', color='#8B0000', zorder=3)\n",
    "                axs[0,1].plot(np.unique(x_nist612), np.poly1d(np.polyfit(x_nist612, y_nist612, 1))(np.unique(x_nist612)), linestyle='--', color='k', alpha=0.2)\n",
    "                    #plot the scatter points with error bars\n",
    "                axs[0,1].scatter(x_nist612,y_nist612, label='Data', marker='o', color='#8B0000', s=25, zorder=2, alpha=.5)\n",
    "                axs[0,1].errorbar(x_nist612,y_nist612, yerr=y_enist612, linestyle=\"None\", color='k', alpha=.3, zorder=1)\n",
    "                    #title and x,y labels\n",
    "                axs[0,1].set_title('Nist-612', fontsize=12)\n",
    "            else:\n",
    "                    ####Plot NIST614 if it was shot\n",
    "                    #create a color span on plot representing the accepted value for the standard\n",
    "                axs[0,1].axhspan(nist614_value-nist614_err, nist614_value+nist614_err, alpha=0.1, color='cornflowerblue')\n",
    "                    #plot the measured mean Uppm line in ref material\n",
    "                axs[0,1].plot(x_nist614,y_mnist614, label='Mean', linestyle='-', color='#8B0000', alpha=0.5)\n",
    "                axs[0,1].text(np.mean(x_nist614), np.mean(y_mnist614) + np.mean(y_mnist614)*0.01,'mean: {0:.2f}'\" \"u'\\xb1'\" \"'{1:.2f}'\" \"'ppm' .format(round(y_mnist614[0], 2),round(y_menist614[0], 2)),fontsize=11, ha='center', color='#8B0000', zorder=3)\n",
    "                axs[0,1].plot(np.unique(x_nist614), np.poly1d(np.polyfit(x_nist614, y_nist614, 1))(np.unique(x_nist614)), linestyle='--', color='k', alpha=0.2)\n",
    "                    #plot the scatter points with error bars\n",
    "                axs[0,1].scatter(x_nist614,y_nist614, label='Data', marker='o', color='#8B0000', s=25, zorder=2, alpha=.5)\n",
    "                axs[0,1].errorbar(x_nist614,y_nist614, yerr=y_enist614, linestyle=\"None\", color='k', alpha=.3, zorder=1)\n",
    "                    #title and x,y labels\n",
    "                axs[0,1].set_title('Nist-614', fontsize=12)\n",
    "                \n",
    "            if len(std_dur['point_name']) != 0:\n",
    "                ####DURANGO\n",
    "                #create a color span on plot representing the accepted value for the standard\n",
    "                axs[1,0].axhspan(dur_value-dur_err, dur_value+dur_err, alpha=0.1, color='cornflowerblue')\n",
    "                #plot the measured mean Uppm line in ref material\n",
    "                axs[1,0].plot(x_dur,y_mdur, label='Mean', linestyle='-', color='#8B0000', alpha=0.5)\n",
    "                axs[1,0].text(np.mean(x_dur), np.mean(y_mdur) + np.mean(y_mdur)*0.01,'mean: {0:.2f}'\" \"u'\\xb1'\" \"'{1:.2f}'\" \"'ppm' .format(round(y_mdur[0], 2),round(y_medur[0], 2)),fontsize=11, ha='center', color='#8B0000', zorder=3)\n",
    "                axs[1,0].plot(np.unique(x_dur), np.poly1d(np.polyfit(x_dur, y_dur, 1))(np.unique(x_dur)), linestyle='--', color='k', alpha=0.2)\n",
    "                #plot the scatter points with error bars\n",
    "                axs[1,0].scatter(x_dur,y_dur, label='Data', marker='o', color='#8B0000', s=25, zorder=2, alpha=.5)\n",
    "                axs[1,0].errorbar(x_dur,y_dur, yerr=y_edur, linestyle=\"None\", color='k', alpha=.3, zorder=1)\n",
    "                #title and x,y labels\n",
    "                axs[1,0].set_title('Durango', fontsize=12)\n",
    "\n",
    "            if len(std_mt['point_name']) != 0:\n",
    "                ####MUD_TANK\n",
    "                #create a color span on plot representing the accepted value for the standard\n",
    "                axs[1,1].axhspan(mt_value-mt_err, mt_value+mt_err, alpha=0.1, color='cornflowerblue')\n",
    "                #plot the measured mean Uppm line in ref material\n",
    "                axs[1,1].plot(x_mt,y_mmt, label='Mean', linestyle='-', color='#8B0000', alpha=0.5)\n",
    "                axs[1,1].text(np.mean(x_mt), np.mean(y_mmt) + np.mean(y_mmt)*0.015,'mean: {0:.2f}'\" \"u'\\xb1'\" \"'{1:.2f}'\" \"'ppm' .format(round(y_mmt[0], 2),round(y_memt[0], 2)),fontsize=11, ha='center', color='#8B0000', zorder=3)\n",
    "                axs[1,1].plot(np.unique(x_mt), np.poly1d(np.polyfit(x_mt, y_mt, 1))(np.unique(x_mt)), linestyle='--', color='k', alpha=0.2)\n",
    "                #plot the scatter points with error bars\n",
    "                axs[1,1].scatter(x_mt,y_mt, label='Data', marker='o', color='#8B0000', s=25, zorder=2, alpha=.5)\n",
    "                axs[1,1].errorbar(x_mt,y_mt, yerr=y_emt, linestyle=\"None\", color='k', alpha=.3, zorder=1)\n",
    "                #title and x,y labels\n",
    "                axs[1,1].set_title('Mud-Tank', fontsize=12)\n",
    "\n",
    "            ####OUTPUT(SAMPLES)\n",
    "            #plot the measured mean Uppm line in ref material\n",
    "            axs[0,0].plot(x_output,y_moutput, label='Mean', linestyle='-', color='#8B0000', alpha=0.5)\n",
    "            axs[0,0].text(np.mean(x_output), np.mean(y_moutput) + np.mean(y_moutput)*0.05,'mean: {0:.2f}'\" \"u'\\xb1'\" \"'{1:.2f}'\" \"'ppm' .format(round(y_moutput[0], 2),round(y_meoutput[0], 2)),fontsize=11, ha='center', color='#8B0000', zorder=3)\n",
    "            axs[0,0].plot(np.unique(x_output), np.poly1d(np.polyfit(x_output, y_output, 1))(np.unique(x_output)), linestyle='--', color='k', alpha=0.2)\n",
    "            #plot the scatter points with error bars\n",
    "            axs[0,0].scatter(x_output,y_output, label='Data', marker='o', color='#8B0000', s=25, zorder=2, alpha=.5)\n",
    "            axs[0,0].errorbar(x_output,y_output, yerr=y_eoutput, linestyle=\"None\", color='k', alpha=.3, zorder=1)\n",
    "            axs[0,0].set_yscale('log')\n",
    "            #title and x,y labels\n",
    "            axs[0,0].set_title('Sample: {}' .format(sample_name), fontsize=12)\n",
    "\n",
    "            for ax in axs.flat:\n",
    "                ax.set(xlabel='time 10e-4 (s)', ylabel='[U] ppm')\n",
    "            # Hide x labels and tick labels for top plots and y ticks for right plots.\n",
    "            #for ax in axs.flat:\n",
    "            #    ax.label_outer()\n",
    "\n",
    "            #padding between sublpots\n",
    "            fig.tight_layout(pad=1.5)\n",
    "\n",
    "            #save the figure to file, location defined at the start\n",
    "            plt.savefig(\"{0}/{1}_Standards.pdf\".format(save_to, sample_name), bbox_inches='tight', transparent=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################IMPORTANT CELL#####################################\n",
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    remove_grains_w = [widgets.ToggleButton(True,description=\"Grain {0}\".format(g),\n",
    "                                        button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "                                        #icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "                                        layout=Layout(flex='0 1 auto',\n",
    "                                        width='auto',)) for g in age_df['Grain/Mica']]\n",
    "\n",
    "\n",
    "\n",
    "    all_boxes = HBox([remove_grains_w[n] for n in range(0,int(round((age_df['Grain/Mica'].count()))))])\n",
    "    \n",
    "    box_layout = Layout(display='flex',\n",
    "                    flex_flow='row wrap',\n",
    "                    border='solid 0px',\n",
    "                    width='100%')\n",
    "    \n",
    "    box = Box(children=remove_grains_w, layout=box_layout)\n",
    "    print(\"REMOVE GRAINS FROM AGE EQUATION\\n   Include\\Exclude Grains:\")\n",
    "    display(widgets.HBox([box]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "        ###SEE ONLY THOSE GRAINS THAT HAVE SOMETHING IN THE NOTES COLUMN####\n",
    "    grain_notes = age_df[age_df['Notes'].notnull()]\n",
    "    grain_notes = grain_notes[[\"Grain/Mica\", \"Tracks\", \"Area(cm2)\",\n",
    "                               \"Density(tracks/cm2)\", 'Average DPar(µmm)',\n",
    "                               \"U_ppm_m238\", \"Notes\",]]\n",
    "    print(\"GRAINS WITH NOTES (for your review):\")\n",
    "    display(grain_notes.style.hide_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:    \n",
    "    print(\"6) CALCULATE/RE-CALCULATE THE AGE(S)\")\n",
    "    def calc_age(b):\n",
    "        display(Javascript('IPython.notebook.execute_cells_below()'))\n",
    "        #display(Javascript('IPython.notebook.execute_cells([14,15,16,17,18,19,20,21])'))\n",
    "    calc_age_button = widgets.Button(description = \"Calculate/Re-calculate Age\",\n",
    "                                    layout=Layout(width='90%'),button_style='success')\n",
    "\n",
    "\n",
    "\n",
    "    calc_age_button.on_click(calc_age)\n",
    "    display(calc_age_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    ####DEFINE VARIABLES IN THE DATAFRAM(S) USED TO CLACULATE AGES, ETC..####\n",
    "\n",
    "    ns = age_df['Tracks']\n",
    "    area = age_df['Area(cm2)']\n",
    "    ps = age_df['Tracks']/age_df['Area(cm2)']\n",
    "    U_ppm = age_df['U_ppm_m238']\n",
    "    U_ppm_1sigma = age_df['U_ppm_m238_Int2SE']/2\n",
    "    Th_ppm = age_df['Th_ppm_m232']\n",
    "    Th_ppm_1sigma = age_df['Th_ppm_m232_Int2SE']/2\n",
    "    Dpar = age_df['Average DPar(µmm)']\n",
    "    Dpar_mean = round(np.mean(Dpar),2)\n",
    "    Dpar_1sigma = age_df['DPar Std Deviation']\n",
    "    no_grains=ps.count()\n",
    "    grain_id=age_df['Grain/Mica']\n",
    "    eU = U_ppm+(0.245*Th_ppm)\n",
    "    eU_1sigma = U_ppm_1sigma+0.245*Th_ppm_1sigma\n",
    "    \n",
    "    if etchant == '5M HNO3'and rmr0pref == '2007':\n",
    "        rmr0D = round(0.84*((4.58-(0.9231*Dpar+0.2515))/2.98)**(0.21),3)\n",
    "    elif etchant == '5M HNO3'and rmr0pref == '1999':\n",
    "        rmr0D = round(1-np.exp(0.647*((0.9231*Dpar+0.2515)-1.75)-1.834),3)\n",
    "    elif etchant == '5.5M HNO3' and rmr0pref == '2007':\n",
    "        rmr0D = round(0.84*((4.58-(Dpar))/2.98)**(0.21),3)\n",
    "    elif etchant == '5.5M HNO3'and rmr0pref == '1999':\n",
    "        rmr0D = round(1-np.exp(0.647*(Dpar-1.75)-1.834),3)\n",
    "\n",
    "        #checks if there is a column in the age_df dataframe named \"Cl\" (if you've added Cl data)\n",
    "    if 'Cl' in age_df.columns:\n",
    "        Cl_sem = round(age_df['Cl'],3)\n",
    "        rmr0 = round(age_df['rmr0'],3)\n",
    "    else:\n",
    "        Cl_sem = '--'\n",
    "    if 'rmr0' in age_df.columns and eCLpref == '2007':\n",
    "        eCL = round(1-(((rmr0/0.857015)**(1/0.23))+0.13),3)\n",
    "    elif 'rmr0' in age_df.columns and eCLpref == '1999':\n",
    "        eCL = round((np.log(1-rmr0)+1.834)/(2.107),3)\n",
    "    else:\n",
    "        rmr0 = '--'\n",
    "        eCL = '--'\n",
    "\n",
    "    \n",
    "        #generate SGA\n",
    "    ri = U_ppm/((area)*((U_ppm_1sigma)**2)) #estimate rho for 0 track grains, re-arrange eq 18 vermeesch 2017, using 0 for Xi error\n",
    "    ni = (U_ppm/U_ppm_1sigma)**2\n",
    "        #Handles zero track grains after Vermeesch, 2017\n",
    "            #in the case of 0 tracks, eq 14 from vermeesch, where his 1/2zeta == Chi\n",
    "    Age_sga = np.where(ns==0., 1/ld*np.log(1+(Xi)*ld*ri*((ns+0.5)/(ni+0.5))), (1/(ld)*np.log(1+Xi*ld*ps/U_ppm)))\n",
    "    Age_sga_1sigma = np.where(ns==0., Age_sga*(1/(ns+0.5)+1/(ni+0.5))**(0.5), (1/(ld)*np.log(1+Xi*ld*ps/U_ppm))*(((1/ns)+(U_ppm_1sigma/U_ppm)**(2))**(0.5)))\n",
    "    ps = np.where(ns==0., ri, ps)\n",
    "\n",
    "    #Generate Pooled age\n",
    "    Pooled_age = (1/(ld)*np.log(1+Xi*ld*np.sum(ns)/np.sum(U_ppm*area)))\n",
    "        #pooled age error\n",
    "    f_Ti=1/(((2*np.pi)**(0.5))*Age_sga_1sigma/Age_sga)\n",
    "    f_Ti_k=f_Ti/np.sum(f_Ti)\n",
    "    Pooled_age_1sigma = (np.sum(((Age_sga-Pooled_age)**2)*f_Ti_k)**0.5)/(no_grains-1)**0.5\n",
    "\n",
    "    #chi-square test\n",
    "        #Calculates X2 after Vermeesch, 2017 (same as radial plotter X2)\n",
    "    zj = np.log(Age_sga)\n",
    "    sj = Age_sga_1sigma/Age_sga\n",
    "    X2 = np.sum((zj/sj)**2)-((np.sum(zj/(sj**2)))**2)/(np.sum(1/(sj**2))) #X2 from Vermeesch 2017\n",
    "    PX2_perc = stats.chi2.sf(X2, no_grains-1)*100\n",
    "\n",
    "    #central age and dispersion is calculated later\n",
    "\n",
    "        #create a new dataframe with the ages etc..\n",
    "            #(sorry for naming standard deviation 4 diff things, cant use same object twice..)\n",
    "    ns_df = pd.DataFrame({'Grain ID': grain_id, 'Ns': ns, 'Area (cm2)': area,\n",
    "                          'ps (cm2)': ps, '238U (ppm)': U_ppm, '±':'±','1SD(U)': U_ppm_1sigma,\n",
    "                          '232U (ppm)': Th_ppm, '±':'±','1SD(Th)': Th_ppm_1sigma,\n",
    "                           'eU (ppm)': eU,'±2':'±', '1SD(eU)': eU_1sigma, 'Age(Ma)': Age_sga,\n",
    "                          '±3':'±','1SD(Age)': Age_sga_1sigma,'Dpar (µm)': Dpar,\n",
    "                          '±4':'±','1SD(Dp)': Dpar_1sigma, 'Cl wt (%)': Cl_sem,\n",
    "                          'rmr0': rmr0, 'rmr0D': rmr0D, 'eCL': eCL})\n",
    "\n",
    "    ns_df.reset_index(drop=True, inplace=True)\n",
    "    #ns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    remove_grs = []\n",
    "    for i in range(0,age_df['Grain/Mica'].count()):\n",
    "        if remove_grains_w[i].value == False:\n",
    "            remove_grs.append(remove_grains_w[i].description)\n",
    "            #remove the words 'Grain ' from the removed_grain list as this will break other things if left in\n",
    "            remove_grs = [x.replace('Grain ', '') for x in remove_grs]\n",
    "    ns_df = ns_df[~ns_df['Grain ID'].isin(remove_grs)]\n",
    "    \n",
    "        #removes grains with [U] = 0, aka \"Below LOD\" that give an age of 'infinity' and break my code :(\n",
    "    ns_df = ns_df[ns_df['238U (ppm)'] != 0.]\n",
    "        #removes grains that haven't been counted in FastTracks based on \"0\" measured area of interest\n",
    "    ns_df = ns_df[ns_df['Area (cm2)'] != 0.]\n",
    "\n",
    "    #adds removed grains from above to new list: ns_df_removed\n",
    "    ns_df_removed = age_df[age_df['Grain/Mica'].isin(remove_grs)]\n",
    "    ns_df_removed = ns_df_removed.append(age_df[age_df['Area(cm2)'] == 0])\n",
    "    ns_df_removed = ns_df_removed.append(age_df[age_df['U_ppm_m238'] == 0])\n",
    "    ns_df_removed.drop_duplicates(subset =\"Grain/Mica\",keep = 'first', inplace = True)\n",
    "        #notes reason for removal in column\n",
    "    ns_df_removed.insert(1, 'Reason for removal', 'User Removed')\n",
    "    ns_df_removed.loc[ns_df_removed['U_ppm_m238'] == 0, 'Reason for removal'] = \"[U] Below detection limit\"\n",
    "    ns_df_removed.loc[ns_df_removed['Area(cm2)'] == 0, 'Reason for removal'] = \"Did not measure\"\n",
    "        #select column headers we want; remove unwanted columns\n",
    "    ns_df_removed = ns_df_removed[['Grain/Mica','Reason for removal','Tracks','U_ppm_m238','Notes']]\n",
    "\n",
    "        #inspect the grains you've removed, make sure you've removed the correct grains\n",
    "    print(\"GRAINS REMOVED FROM AGE EQUATION:\")\n",
    "    display(ns_df_removed.style.hide_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []: \n",
    "    ####RE-CALCULATE NEW AGES BASED ON THE REMOVAL OF GRAINS, FINALLY CALCULATES THE CENTRAL AGE####\n",
    "\n",
    "    ns = ns_df['Ns']\n",
    "    area = ns_df['Area (cm2)']\n",
    "    ps = ns_df['Ns']/ns_df['Area (cm2)']\n",
    "    U_ppm = ns_df['238U (ppm)']\n",
    "    U_ppm_1sigma = ns_df['1SD(U)']\n",
    "    Th_ppm = ns_df['232U (ppm)']\n",
    "    Th_ppm_1sigma = ns_df['1SD(Th)']\n",
    "    Dpar = ns_df['Dpar (µm)']\n",
    "    Dpar_mean = round(np.mean(Dpar),2)\n",
    "    Dpar_1sigma = ns_df['1SD(Dp)']\n",
    "    no_grains=ps.count()\n",
    "    grain_id=ns_df['Grain ID']\n",
    "    eU = ns_df['eU (ppm)']\n",
    "    eU_1sigma = ns_df['1SD(eU)']\n",
    "    Cl_sem = ns_df['Cl wt (%)']\n",
    "    rmr0 = ns_df['rmr0']\n",
    "    rmr0D = ns_df['rmr0D']\n",
    "    eCL = ns_df['eCL']\n",
    "\n",
    "        #checks if there is a column in the age_df dataframe named \"Cl\" (if you've added Cl data)\n",
    "    if 'Cl' in age_df.columns:\n",
    "        Cl_sem_mean = round(np.mean(Cl_sem),3)\n",
    "        Cl_sem_sdm = round(np.std(Cl_sem), 3)\n",
    "    else:\n",
    "        Cl_sem_mean = '--'\n",
    "        Cl_sem_sdm = '--'\n",
    "    if 'rmr0' in age_df.columns:\n",
    "        rmr0_mean = round(np.mean(rmr0),3)\n",
    "        rmr0_sdm = round(np.std(rmr0), 3)\n",
    "        eCL_mean = round(np.mean(eCL), 3)\n",
    "        eCL_sdm = round(np.std(eCL), 3)\n",
    "    else:\n",
    "        rmr0_mean = '--'\n",
    "        rmr0_sdm = '--'\n",
    "        eCL_mean = '--'\n",
    "        eCL_sdm = '--'\n",
    "\n",
    "    rmr0D_mean = round(np.mean(rmr0D),3)\n",
    "    rmr0D_sdm = round(np.std(rmr0D), 3)\n",
    "\n",
    "    #generate SGA\n",
    "    ri = U_ppm/((area)*((U_ppm_1sigma)**2)) #estimate rho for 0 track grains, re-arrange eq 18 vermeesch 2017, using 0 for Xi error\n",
    "    ni = (U_ppm/U_ppm_1sigma)**2\n",
    "        #Handles zero track grains after Vermeesch, 2017\n",
    "            #in the case of 0 tracks, eq 14 from vermeesch, where his 1/2zeta == Chi\n",
    "    Age_sga = np.where(ns==0., 1/ld*np.log(1+(Xi)*ld*ri*((ns+0.5)/(ni+0.5))), (1/(ld)*np.log(1+Xi*ld*ps/U_ppm)))\n",
    "    Age_sga_1sigma = np.where(ns==0., Age_sga*(1/(ns+0.5)+1/(ni+0.5))**(0.5), (1/(ld)*np.log(1+Xi*ld*ps/U_ppm))*(((1/ns)+(U_ppm_1sigma/U_ppm)**(2))**(0.5)))\n",
    "    ps = np.where(ns==0., ri, ps)\n",
    "\n",
    "    #Pooled age\n",
    "    Pooled_age = (1/(ld)*np.log(1+Xi*ld*np.sum(ns)/np.sum(U_ppm*area)))\n",
    "    #pooled age error\n",
    "    f_Ti=1/(((2*np.pi)**(0.5))*Age_sga_1sigma/Age_sga)\n",
    "    f_Ti_k=f_Ti/np.sum(f_Ti)\n",
    "    Pooled_age_1sigma = (np.sum(((Age_sga-Pooled_age)**2)*f_Ti_k)**0.5)/(no_grains-1)**0.5\n",
    "\n",
    "\n",
    "    #chi-square test\n",
    "        #Calculates X2 after Vermeesch, 2017 (same as radial plotter X2, different from excel dating sheet)\n",
    "    zj = np.log(Age_sga)\n",
    "    sj = Age_sga_1sigma/Age_sga\n",
    "    X2 = np.sum((zj/sj)**2)-((np.sum(zj/(sj**2)))**2)/(np.sum(1/(sj**2))) #X2 from Vermeesch 2017\n",
    "    PX2_perc = stats.chi2.sf(X2, no_grains-1)*100\n",
    "    if PX2_perc <= 4.99:\n",
    "        chi_test = 'Fail'\n",
    "    else:\n",
    "        chi_test = 'Pass'\n",
    "\n",
    "    ns_df = pd.DataFrame({'Grain ID': grain_id, 'Ns': ns, 'Area (cm2)': area,\n",
    "                          'ps (cm2)': ps, '238U (ppm)': U_ppm, '±':'±','1SD(U)': U_ppm_1sigma, \n",
    "                          '232U (ppm)': Th_ppm, '±':'±','1SD(Th)': Th_ppm_1sigma,\n",
    "                           'eU (ppm)': eU,'±2':'±', '1SD(eU)': eU_1sigma, 'Age(Ma)': Age_sga,\n",
    "                          '±3':'±','1SD(Age)': Age_sga_1sigma,'Dpar (µm)': Dpar,\n",
    "                          '±4':'±','1SD(Dp)': Dpar_1sigma, 'Cl wt (%)': Cl_sem,\n",
    "                          'rmr0': rmr0, 'rmr0D': rmr0D, 'eCL' : eCL})\n",
    "\n",
    "    ns_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    #Central age and dispersion\n",
    "        #uses the CentralAge.py function, should exist in the same folder as this py project.\n",
    "        #expects 4 arguments in this order CentralAge(grain_ids, single_grain_ages, single_grain_1sigma, pooled_age)\n",
    "        #grain ids should be something that it can get the total grain count\n",
    "    C_A = CentralAge(ns_df['Grain ID'], ns_df['Age(Ma)'], ns_df['1SD(Age)'], Pooled_age)\n",
    "        #returns 3 variables, in this order: Central Age, Central Age 1sigma, Dispersion\n",
    "    Central_age = C_A[0]\n",
    "    Central_age_1sigma = C_A[1]\n",
    "    Dispersion = C_A[2]\n",
    "\n",
    "    print('Pooled Age:', round(Pooled_age, 2), '±', round(Pooled_age_1sigma,2),'Ma')\n",
    "    print('Central Age:', round(Central_age, 2), '±', round(Central_age_1sigma, 2),'Ma')\n",
    "    print('No. of grains: ',grain_id.count())\n",
    "    print('---------')\n",
    "    print('X2:', round(X2, 2))\n",
    "    print('P(X2):', round(PX2_perc, 2),'%')\n",
    "    print('Dispersion:', round(Dispersion,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    ns_df_sorted = ns_df.sort_values(by='Age(Ma)')\n",
    "    ns_df_sorted.reset_index(drop=True, inplace=True)\n",
    "    Age_sga_sorted = ns_df_sorted['Age(Ma)']\n",
    "    Age_sga_1sigma_sorted = ns_df_sorted['1SD(Age)']\n",
    "    \n",
    "    no_grains_sorted=Age_sga_sorted.count()\n",
    "    grain_id_sorted=ns_df_sorted['Grain ID']\n",
    "\n",
    "    U_ppm_sorted = ns_df_sorted['238U (ppm)']\n",
    "    U_ppm_1sigma_sorted = ns_df_sorted['1SD(U)']\n",
    "    \n",
    "    eU_ppm_sorted = ns_df_sorted['eU (ppm)']\n",
    "    eU_ppm_1sigma_sorted = ns_df_sorted['1SD(eU)']\n",
    "    \n",
    "    Dpar_sorted = ns_df_sorted['Dpar (µm)']\n",
    "    Dpar_1sigma_sorted = ns_df_sorted['1SD(Dp)']\n",
    "\n",
    "    ages_enumerated = []\n",
    "    for i, ages in enumerate(Age_sga_sorted):\n",
    "        ages_e = ages/ages+i\n",
    "        ages_enumerated.append(ages_e)\n",
    "        \n",
    "    eU_enumerated = []\n",
    "    for i, eU_s in enumerate(eU_ppm_sorted):\n",
    "        eU_e = eU_s/eU_s+i\n",
    "        eU_enumerated.append(eU_e)\n",
    "        \n",
    "    Dpar_enumerated = []\n",
    "    for i, Dpar_s in enumerate(Dpar_sorted):\n",
    "        Dpar_e = Dpar_s/Dpar_s+i\n",
    "        Dpar_enumerated.append(Dpar_e)\n",
    "        \n",
    "    # noramlize the color bar based on the mean\n",
    "    class MidpointNormalize(mpl.colors.Normalize):\n",
    "        def __init__(self, vmin=None, vmax=None, vcenter=None, clip=False):\n",
    "            self.vcenter = vcenter\n",
    "            mpl.colors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "        def __call__(self, value, clip=None):\n",
    "            # I'm ignoring masked values\n",
    "            x, y = [self.vmin, self.vcenter, self.vmax], [0, 0.5, 1]\n",
    "            return np.ma.masked_array(np.interp(value, x, y))\n",
    "        \n",
    "    midnorm_eU = MidpointNormalize(vmin=min(eU_ppm_sorted),\n",
    "                                   vcenter=np.mean(eU_ppm_sorted), vmax=max(eU_ppm_sorted))\n",
    "    \n",
    "    midnorm_Dpar = MidpointNormalize(vmin=min(Dpar_sorted),\n",
    "                                     vcenter=np.mean(Dpar_sorted), vmax=max(Dpar_sorted))\n",
    "    \n",
    "    #lay out the figures using GridSpec\n",
    "    fig1 = plt.figure(constrained_layout=True, figsize=(16,14))\n",
    "    spec1 = gs.GridSpec(ncols=3, nrows=2, figure=fig1, width_ratios=(10,0.3,10))\n",
    "\n",
    "        #upper left figure\n",
    "    ax = fig1.add_subplot(spec1[0, 0])\n",
    "        #plot the scatter points with error bars\n",
    "    ax.hist(Age_sga_sorted, bins = int(grain_id.count()/2),\n",
    "             color = 'grey', edgecolor = 'black', orientation=\"horizontal\", alpha=0.20)\n",
    "    eUcolor = ax.scatter(ages_enumerated,Age_sga_sorted, marker='s', c=eU_ppm_sorted, cmap='coolwarm',\n",
    "               s=140, alpha=0.6, norm=midnorm_eU, zorder=2, label='_nolegend_')\n",
    "    ax.errorbar(ages_enumerated,Age_sga_sorted, yerr=Age_sga_1sigma_sorted,\n",
    "                linestyle=\"None\", c='k', alpha=0.2, linewidth=2.5,zorder=1, label='_nolegend_')\n",
    "        #annotate each plot point with grain id\n",
    "    for i, txt in enumerate(grain_id_sorted):\n",
    "        ax.annotate(txt, (ages_enumerated[i], Age_sga_sorted[i]), fontsize=9, weight = 'bold',\n",
    "                    ha='center', va='center', color='k',alpha=0.8,zorder=3)\n",
    "\n",
    "    ax.set_yscale('linear') #change to log if you wish\n",
    "    ax.autoscale(enable=True, axis='y', tight=True)\n",
    "        #color span for pooled & central age ranges\n",
    "    ax.axhspan(Pooled_age-Pooled_age_1sigma, Pooled_age+Pooled_age_1sigma, alpha=0.2,\n",
    "               edgecolor = 'k',facecolor='none',linestyle='--',linewidth=1.5, label='P. Age±SD', zorder=4)\n",
    "    ax.axhspan(Central_age-Central_age_1sigma, Central_age+Central_age_1sigma, alpha=0.2,\n",
    "               color='cornflowerblue', label='C. Age±SD', zorder=5)\n",
    "        #titles and other text\n",
    "    ax.legend(loc='upper right')\n",
    "    if ns_df_removed['Grain/Mica'].empty:\n",
    "        ax.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count()),\n",
    "                style='italic', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "    else:\n",
    "        ax.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}\\n Removed GrainID(s):\\n{9}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count(),\n",
    "        ns_df_removed['Grain/Mica'].to_string(index=False)), style='italic', horizontalalignment='left', verticalalignment='top', transform=ax.transAxes, fontsize=11)\n",
    "    ax.set_title('{0} Single Grain Ages' .format(sample_name))\n",
    "    ax.set_ylabel('Age (Ma)', fontsize=12)\n",
    "    ax.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "\n",
    "    ax3 = plt.subplot(spec1[0, 1])\n",
    "    c_bar = plt.colorbar(eUcolor, cax=ax3)\n",
    "    c_bar.set_label(\"[eU]ppm\", fontsize=10)\n",
    "\n",
    "    ##### upper right figure\n",
    "    ax2 = fig1.add_subplot(spec1[0, 2])\n",
    "    euplot = ax2.scatter(x=eU_enumerated,y=eU_ppm_sorted,marker='o', color='white', s=100, alpha=1, zorder=2)\n",
    "    ax2.errorbar(x=eU_enumerated,y=eU_ppm_sorted, yerr=eU_ppm_1sigma_sorted, linestyle=\"None\", linewidth=2.5,color='k', alpha=0.2, zorder=1)\n",
    "    ax2.grid(which='major', axis='y', alpha=0.6)    \n",
    "    ax2.grid(which='minor', axis='y', alpha=0.2)   \n",
    "        #annotate each plot point with grain number\n",
    "    for i, txt in enumerate(grain_id_sorted):\n",
    "        ax2.annotate(txt, (eU_enumerated[i], eU_ppm_sorted[i]), fontsize=9, weight = 'bold', ha='center', va='center', color='#942222', zorder=3)\n",
    "    #for i,j in zip(grain_id,eU):\n",
    "    #    ax2.annotate(str(i),xy=(i,j), fontsize=9, weight = 'bold', ha='center', va='center', color='#90033C', zorder=3)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.yaxis.set_label_position(\"right\")\n",
    "    ax2.yaxis.tick_right()\n",
    "        #color span for u±1sigma\n",
    "    ax2.axhspan(np.mean(eU)-np.std(eU), \n",
    "                np.mean(eU)+np.std(eU), \n",
    "                alpha=0.2, color='cornflowerblue')\n",
    "        #draw line at less than 1 ppm, consider removing these grains (anonymously old usualy)\n",
    "    ax2.axhline(y=1,linewidth=1, linestyle='--', color='#970000')\n",
    "    ax2.axhspan(1, 0, alpha=0.1, color='r')\n",
    "        #plot text that appears inside the plot\n",
    "    ax2.text(min(i for i in eU_enumerated if not math.isnan(i)), (np.mean(eU)+np.std(eU))*0.80, \n",
    "             'mean [eU]: {0:.2f}±{1:.1f}ppm'.format(np.mean(eU),np.std(eU)), \n",
    "             style='italic', horizontalalignment='left', fontsize=10, color='cornflowerblue')\n",
    "\n",
    "        #titles and other text\n",
    "    #ax2.legend(loc='upper right')\n",
    "    ax2.set_title('{0} [eU] ppm' .format(sample_name))\n",
    "    ax2.set_ylabel('[eU] ppm', fontsize=12)\n",
    "    ax2.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "\n",
    "    #######################################\n",
    "    #plot age vs cl info\n",
    "    if 'Cl' in age_df.columns:\n",
    "        eCL_sorted = ns_df_sorted['eCL']\n",
    "        #eCL_1sigma_sorted = ns_df_sorted['1SD(Dp)']\n",
    "        midnorm_eCL = MidpointNormalize(vmin=min(eCL_sorted), vcenter=np.mean(eCL_sorted), vmax=max(eCL_sorted))\n",
    "        #eCL_enumerated = []\n",
    "        #for i, eCL_s in enumerate(eCL_sorted):\n",
    "        #    eCL_e = eCL_s/eCL_s+i\n",
    "        #    eCL_enumerated.append(eCL_e)\n",
    "            #lower left figure\n",
    "        ax4 = fig1.add_subplot(spec1[1, 0])\n",
    "            #plot the scatter points with error bars\n",
    "        ax4.hist(Age_sga_sorted, bins = int(grain_id.count()/2),\n",
    "                 color = 'grey', edgecolor = 'black', orientation=\"horizontal\", alpha=0.20)\n",
    "        cmap = plt.get_cmap('PiYG')\n",
    "        cmap.set_bad(\"yellow\")\n",
    "        eCLcolor = ax4.scatter(ages_enumerated,Age_sga_sorted, marker='s', c=eCL_sorted, cmap=cmap,\n",
    "                    plotnonfinite=True, vmin=np.min(eCL_sorted), vmax=np.max(eCL_sorted),\n",
    "                   s=140, alpha=0.6, norm=midnorm_eCL, zorder=2, label='_nolegend_')\n",
    "        ax4.errorbar(ages_enumerated,Age_sga_sorted, yerr=Age_sga_1sigma_sorted,\n",
    "                    linestyle=\"None\", c='k', alpha=0.2, linewidth=2.5,zorder=1, label='_nolegend_')\n",
    "            #annotate each plot point with grain id\n",
    "        for i, txt in enumerate(grain_id_sorted):\n",
    "            ax4.annotate(txt, (ages_enumerated[i], Age_sga_sorted[i]), fontsize=9, weight = 'bold',\n",
    "                        ha='center', va='center', color='k',alpha=0.8,zorder=3)\n",
    "\n",
    "        ax4.set_yscale('linear') #change to log if you wish\n",
    "        ax4.autoscale(enable=True, axis='y', tight=True)\n",
    "            #color span for pooled & central age ranges\n",
    "        ax4.axhspan(Pooled_age-Pooled_age_1sigma, Pooled_age+Pooled_age_1sigma, alpha=0.2,\n",
    "                   edgecolor = 'k',facecolor='none',linestyle='--',linewidth=1.5, label='P. Age±SD', zorder=4)\n",
    "        ax4.axhspan(Central_age-Central_age_1sigma, Central_age+Central_age_1sigma, alpha=0.2,\n",
    "                   color='cornflowerblue', label='C. Age±SD', zorder=5)\n",
    "            #titles and other text\n",
    "        ax4.legend(loc='upper right')\n",
    "        if ns_df_removed['Grain/Mica'].empty:\n",
    "            ax4.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count()),\n",
    "                    style='italic', horizontalalignment='left', verticalalignment='top', transform=ax4.transAxes, fontsize=11)\n",
    "        else:\n",
    "            ax4.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}\\n Removed GrainID(s):\\n{9}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count(),\n",
    "            ns_df_removed['Grain/Mica'].to_string(index=False)), style='italic', horizontalalignment='left', verticalalignment='top', transform=ax4.transAxes, fontsize=11)\n",
    "        ax4.set_title('{0} Single Grain Ages' .format(sample_name))\n",
    "        ax4.set_ylabel('Age (Ma)', fontsize=12)\n",
    "        ax4.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "\n",
    "        ax5 = plt.subplot(spec1[1, 1])\n",
    "        c_bar = plt.colorbar(eCLcolor, cax=ax5)\n",
    "        c_bar.set_label(\"eCL (apfu)\", fontsize=10)\n",
    "\n",
    "        ##### lower right figure\n",
    "        ax6 = fig1.add_subplot(spec1[1, 2])\n",
    "        Dparplot = ax6.scatter(x=ages_enumerated,y=eCL_sorted,marker='o', color='white', s=100, alpha=1, zorder=2)\n",
    "        ax6.grid(which='major', axis='y', alpha=0.5, linestyle=\"--\")    \n",
    "        #ax6.grid(which='minor', axis='y', alpha=0.2)   \n",
    "            #annotate each plot point with grain number\n",
    "        for i, txt in enumerate(grain_id_sorted):\n",
    "            ax6.annotate(txt, (ages_enumerated[i], eCL_sorted[i]), fontsize=9,\n",
    "                         weight = 'bold', ha='center', va='center', color='#942222', zorder=3)\n",
    "\n",
    "        ax6.yaxis.set_label_position(\"right\")\n",
    "        ax6.yaxis.tick_right()\n",
    "            #color span for dpar±1sigma\n",
    "        ax6.axhspan(np.mean(eCL)-np.std(eCL), np.mean(eCL)+np.std(eCL),\n",
    "                    alpha=0.2, color='cornflowerblue')\n",
    "            #plot text that appears inside the plot\n",
    "        ax6.text(min(i for i in ages_enumerated if not math.isnan(i)), np.mean(eCL)+np.std(eCL)*0.8, \n",
    "                 'mean eCl: {0:.3f}±{1:.3f} apfu'.format(np.mean(eCL),np.std(eCL)) ,\n",
    "                 style='italic', horizontalalignment='left', fontsize=10, color='cornflowerblue')\n",
    "\n",
    "            #titles and other text\n",
    "        #ax6.legend(loc='upper right')\n",
    "        ax6.set_title('{0} eCl (apfu)' .format(sample_name))\n",
    "        ax6.set_ylabel('eCl (apfu)', fontsize=12)\n",
    "        ax6.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "        \n",
    "       #plot using Dpar if Cl doesnt exisst \n",
    "    else:\n",
    "            #lower left figure\n",
    "        ax4 = fig1.add_subplot(spec1[1, 0])\n",
    "            #plot the scatter points with error bars\n",
    "        ax4.hist(Age_sga_sorted, bins = int(grain_id.count()/2),\n",
    "                 color = 'grey', edgecolor = 'black', orientation=\"horizontal\", alpha=0.20)\n",
    "        cmap = plt.get_cmap('PiYG')\n",
    "        cmap.set_bad(\"yellow\")\n",
    "        Dparcolor = ax4.scatter(ages_enumerated,Age_sga_sorted, marker='s', c=Dpar_sorted, cmap=cmap,\n",
    "                    plotnonfinite=True, vmin=np.min(Dpar_sorted), vmax=np.max(Dpar_sorted),\n",
    "                   s=140, alpha=0.6, norm=midnorm_Dpar, zorder=2, label='_nolegend_')\n",
    "        ax4.errorbar(ages_enumerated,Age_sga_sorted, yerr=Age_sga_1sigma_sorted,\n",
    "                    linestyle=\"None\", c='k', alpha=0.2, linewidth=2.5,zorder=1, label='_nolegend_')\n",
    "            #annotate each plot point with grain id\n",
    "        for i, txt in enumerate(grain_id_sorted):\n",
    "            ax4.annotate(txt, (ages_enumerated[i], Age_sga_sorted[i]), fontsize=9, weight = 'bold',\n",
    "                        ha='center', va='center', color='k',alpha=0.8,zorder=3)\n",
    "\n",
    "        ax4.set_yscale('linear') #change to log if you wish\n",
    "        ax4.autoscale(enable=True, axis='y', tight=True)\n",
    "            #color span for pooled & central age ranges\n",
    "        ax4.axhspan(Pooled_age-Pooled_age_1sigma, Pooled_age+Pooled_age_1sigma, alpha=0.2,\n",
    "                   edgecolor = 'k',facecolor='none',linestyle='--',linewidth=1.5, label='P. Age±SD', zorder=4)\n",
    "        ax4.axhspan(Central_age-Central_age_1sigma, Central_age+Central_age_1sigma, alpha=0.2,\n",
    "                   color='cornflowerblue', label='C. Age±SD', zorder=5)\n",
    "            #titles and other text\n",
    "        ax4.legend(loc='upper right')\n",
    "        if ns_df_removed['Grain/Mica'].empty:\n",
    "            ax4.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count()),\n",
    "                    style='italic', horizontalalignment='left', verticalalignment='top', transform=ax4.transAxes, fontsize=11)\n",
    "        else:\n",
    "            ax4.text(0.01, 0.99, 'Pooled Age = {0:.1f} ± {1:.1f}Ma\\nCentral Age = {2:.1f} ± {3:.1f}Ma\\n χ2 = {4:.1f}\\n p(χ2) = {5:.1f}% ({6})\\n Disp. = {7:.1f}%\\n\\n Total Grains = {8}\\n Removed GrainID(s):\\n{9}'.format(Pooled_age, Pooled_age_1sigma, Central_age, Central_age_1sigma, X2, PX2_perc, chi_test, Dispersion, grain_id.count(),\n",
    "            ns_df_removed['Grain/Mica'].to_string(index=False)), style='italic', horizontalalignment='left', verticalalignment='top', transform=ax4.transAxes, fontsize=11)\n",
    "        ax4.set_title('{0} Single Grain Ages' .format(sample_name))\n",
    "        ax4.set_ylabel('Age (Ma)', fontsize=12)\n",
    "        ax4.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "\n",
    "        ax5 = plt.subplot(spec1[1, 1])\n",
    "        c_bar = plt.colorbar(Dparcolor, cax=ax5)\n",
    "        c_bar.set_label(\"Dpar (µm)\", fontsize=10)\n",
    "\n",
    "        ##### lower right figure\n",
    "        ax6 = fig1.add_subplot(spec1[1, 2])\n",
    "        Dparplot = ax6.scatter(x=Dpar_enumerated,y=Dpar_sorted,marker='o', color='white',\n",
    "                              s=100, alpha=1, zorder=2)\n",
    "        ax6.errorbar(x=Dpar_enumerated,y=Dpar_sorted, yerr=Dpar_1sigma_sorted, linestyle=\"None\",\n",
    "                     linewidth=2.5,color='k', alpha=0.2, zorder=1)\n",
    "        ax6.grid(which='major', axis='y', alpha=0.5, linestyle=\"--\")    \n",
    "        #ax6.grid(which='minor', axis='y', alpha=0.2)   \n",
    "            #annotate each plot point with grain number\n",
    "        for i, txt in enumerate(grain_id_sorted):\n",
    "            ax6.annotate(txt, (Dpar_enumerated[i], Dpar_sorted[i]), fontsize=9,\n",
    "                         weight = 'bold', ha='center', va='center', color='#942222', zorder=3)\n",
    "\n",
    "        ax6.yaxis.set_label_position(\"right\")\n",
    "        ax6.yaxis.tick_right()\n",
    "            #color span for dpar±1sigma\n",
    "        ax6.axhspan(np.mean(Dpar)-np.mean(Dpar_1sigma), np.mean(Dpar)+np.mean(Dpar_1sigma),\n",
    "                    alpha=0.2, color='cornflowerblue')\n",
    "            #plot text that appears inside the plot\n",
    "        ax6.text(min(i for i in Dpar_enumerated if not math.isnan(i)), \n",
    "                 np.mean(Dpar)+np.mean(Dpar_1sigma)*0.8, 'mean Dpar: {0:.2f}±{1:.1f} µm'.format(np.mean(Dpar),np.mean(Dpar_1sigma)) ,\n",
    "                 style='italic', horizontalalignment='left', fontsize=10, color='cornflowerblue')\n",
    "\n",
    "            #titles and other text\n",
    "        #ax6.legend(loc='upper right')\n",
    "        ax6.set_title('{0} Dpar (µm)' .format(sample_name))\n",
    "        ax6.set_ylabel('Dpar (µm)', fontsize=12)\n",
    "        ax6.set_xlabel('Ascending count based on age', fontsize=12)\n",
    "\n",
    "\n",
    "        #save the figure to file, location defined at the start\n",
    "    plt.savefig(\"{0}/{1}_GrainvAge_eU.pdf\".format(save_to, sample_name), bbox_inches='tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    #Finally, save and export summary table and other sheets to import into modelling prog.\n",
    "    \n",
    "    #modify variables depending on if found in FastTracks file or inserted in text boxes at start\n",
    "    if sample_name_w.value == '':\n",
    "        sample_name = sample_FT\n",
    "    \n",
    "    if igsn_w.value == '':\n",
    "        igsn = igsn_FT\n",
    "    if igsn_FT == '':\n",
    "        igsn = '--'\n",
    "    \n",
    "    if analyst_w.value == '':\n",
    "        analyst = analyst_FT\n",
    "\n",
    "    #Create summary table to single grain ages:\n",
    "        #header\n",
    "    single_grain_header = pd.DataFrame({'col0':['Sample:','IGSN:','Mineral:', 'Rock Type:', \n",
    "                                                'Lat/Long:', 'Elevation:', '','Grain ID'],\n",
    "                                       'col1':['', '', '', '', '', '','','Ns'],\n",
    "                                       'col2':[sample_name,igsn,mineral,rock_type,'{0:.5f}'.format(latitude),\n",
    "                                               '{0} m'.format(elevation),'','Area (cm2)'],\n",
    "                                       'col3':['', '', '', '','/{0:.5f}'.format(longitude), '','','ρS (cm-2)'],\n",
    "                                       'col4':['', '', '', '', '', '','','[U] (ppm)'],\n",
    "                                       'col5':['', '', '', '', '', '','','±'],\n",
    "                                       'col6':['', '', '', '', '', '','','1σ'],\n",
    "                                       'col7':['', '', '', '', '', '','','[Th] (ppm)'],\n",
    "                                       'col8':['', '', '', '', '', '','','±'],\n",
    "                                       'col9':['', '', '', '', '', '','','1σ'],\n",
    "                                       'col10':['', '', '', '', '', '','','e[U] (ppm)'],\n",
    "                                       'col11':['', '', '', '', '', '','','±'],\n",
    "                                       'col12':['', '', '', '', '', '','','1σ'],\n",
    "                                       'col13':['Analyst:', 'Collector:', 'Date Meas.:', 'Software:', \n",
    "                                                'U Stand.:', 'Int. Stand.:','','Age (Ma)'],\n",
    "                                       'col14':['', '', '', '', '', '','','±'],\n",
    "                                       'col15':[analyst,collector,date_meas.strftime(\"%d/%m/%Y\"),\n",
    "                                                software,Ustandard,\n",
    "                                                '{0}, w/ mean [U]: {1}'\" \"u'\\xb1'\" \"'{2}*'\" \"'ppm' .format(Intstandard,mean_intstd,meanerr_intstd),'','1σ'],\n",
    "                                       'col16':['', '', '', '', '', '','','Dpar (µm)'],\n",
    "                                       'col17':['', '', '', '', '', '','','±'],\n",
    "                                       'col18':['', '', '', '', '', '','','SE'],\n",
    "                                       'col19':['', '', '', '', '','','','rmr0†'],\n",
    "                                       'col20':['', '', '', '', '', '','','rmr0\\u1D30‡'],\n",
    "                                       'col21':['', '', '', '', '', '','','Cl (wt%)'],\n",
    "                                       'col22':['', '', '', '', '', '','','eCl (apfu)§']})\n",
    "\n",
    "        #body of single grain ages\n",
    "    single_grain_body = pd.DataFrame({'col0':grain_id,\n",
    "                                        'col1':ns.astype(int),\n",
    "                                        'col2':area,\n",
    "                                        'col3':ps.round(2),\n",
    "                                        'col4':U_ppm.round(2),\n",
    "                                        'col5':'±',\n",
    "                                        'col6':U_ppm_1sigma.round(2),\n",
    "                                        'col7':Th_ppm.round(2),\n",
    "                                        'col8':'±',\n",
    "                                        'col9':Th_ppm_1sigma.round(2),\n",
    "                                        'col10':eU.round(2),\n",
    "                                        'col11':'±',\n",
    "                                        'col12':eU_1sigma.round(2),\n",
    "                                        'col13':Age_sga.round(1),\n",
    "                                        'col14':'±',\n",
    "                                        'col15':Age_sga_1sigma.round(1),\n",
    "                                        'col16':Dpar.round(2),\n",
    "                                        'col17':'±',\n",
    "                                        'col18':Dpar_1sigma.round(2),\n",
    "                                        'col19':rmr0,\n",
    "                                        'col20':rmr0D,\n",
    "                                        'col21':Cl_sem,\n",
    "                                        'col22':eCL.replace(-0.000,0.000),})\n",
    "    single_grain_body = single_grain_body.replace({\"col3\":{0:np.nan}})\n",
    "    single_grain_body = single_grain_body.replace({\"col18\":{0:np.nan}})\n",
    "    \n",
    "    #variables for the footer based on choices at the start\n",
    "    if eCLpref == '2007' and rmr0pref == '2007':\n",
    "        footer_pref = '*std. dev. of mean,   †rmr0 proxy following Ketcham et al. (2007),  ‡rmr0\\u1D30 est. from Dpar (Ketcham et al., 2007),   §effective Cl (Ketcham et al., 2007, McDannell et al., 2019)'\n",
    "    elif eCLpref == '1999' and rmr0pref == '1999':\n",
    "        footer_pref = '*std. dev. of mean,   †rmr0 proxy following Ketcham et al. (1999),  ‡rmr0\\u1D30 est. from Dpar (Ketcham et al., 1999),   §effective Cl (Ketcham et al., 1999, McDannell et al., 2019)'\n",
    "    elif eCLpref == '2007' and rmr0pref == '1999':\n",
    "        footer_pref = '*std. dev. of mean,   †rmr0 proxy following Ketcham et al. (1999),  ‡rmr0\\u1D30 est. from Dpar (Ketcham et al., 1999),   §effective Cl (Ketcham et al., 2007, McDannell et al., 2019)'\n",
    "    elif eCLpref == '1999' and rmr0pref == '2007':\n",
    "        footer_pref = '*std. dev. of mean,   †rmr0 proxy following Ketcham et al. (2007),  ‡rmr0\\u1D30 est. from Dpar (Ketcham et al., 2007),   §effective Cl (Ketcham et al., 1999, McDannell et al., 2019)'\n",
    "        #footer of single grain ages\n",
    "    single_grain_footer = pd.DataFrame({'col0':['',ns.count(), '{0}'.format(footer_pref), '', 'χ2', 'p(χ2)', 'Dispersion'],\n",
    "                                       'col1':['',np.sum(ns).astype(int), '', '', '=', '=', '='],\n",
    "                                       'col2':['',\"{:.3E}\".format(np.sum(area)), '', '',\"{:.1f}\".format(X2),\n",
    "                                               \"{:.1f}%\".format(PX2_perc),\"{:.1f}%\".format(Dispersion)],\n",
    "                                       'col3':['',\"{:.3E}\".format(np.mean(ps)), '', '', '', '({0})'.format(chi_test), ''],\n",
    "                                       'col4':['',\"{:.1f}\".format(np.mean(U_ppm)), '', '', '', '', ''],\n",
    "                                       'col5':['','±', '', '', '', '', ''],\n",
    "                                       'col6':['',\"{:.1f}*\".format(np.std(U_ppm)), '', '', '', '', ''],\n",
    "                                       'col7':['',\"{:.1f}\".format(np.mean(Th_ppm)), '', '', '', '', ''],\n",
    "                                       'col8':['','±', '', '', '', '', ''],\n",
    "                                       'col9':['',\"{:.1f}*\".format(np.std(Th_ppm)), '', '', '', '', ''],\n",
    "                                       'col10':['',\"{:.1f}\".format(np.mean(eU)), '', '', '', '', ''],\n",
    "                                       'col11':['','±', '', '', '', 'Pooled Age =', 'Central Age ='],\n",
    "                                       'col12':['',\"{:.1f}*\".format(np.std(eU)), '', '', '', '', ''],\n",
    "                                       'col13':['','', '', '', '',  \"{:.1f}\".format(Pooled_age),\n",
    "                                                \"{:.1f}\".format(Central_age)],\n",
    "                                       'col14':['','', '', '', '', '±', '±'],\n",
    "                                       'col15':['','','', '', '', \"{:.1f}\".format(Pooled_age_1sigma),\n",
    "                                                \"{:.1f}\".format(Central_age_1sigma)],\n",
    "                                       'col16':['',\"{:.2f}\".format(np.mean(Dpar)), '', '', '','',''],\n",
    "                                       'col17':['','±', '', '', '', '',''],\n",
    "                                       'col18':['',\"{:.2f}*\".format(np.std(Dpar)), '', '', '','',''],\n",
    "                                       'col19':['',rmr0_mean, '', '', '', '', ''],\n",
    "                                       'col20':['',rmr0D_mean, '', '', '', '', ''],\n",
    "                                       'col21':['',Cl_sem_mean, '', '', '', '', ''],\n",
    "                                       'col22':['',eCL_mean, '', '', '', '', '']})\n",
    "\n",
    "    #bin the length data\n",
    "    length_range=[0,1,2,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n",
    "    if mtl != '--':\n",
    "        lengths_summary = lengths_data['True Length'].groupby(pd.cut(lengths_data['True Length'], length_range)).count()\n",
    "        lengths_binned = pd.DataFrame ({\"L1\":['','','','','','','','Length (µm)','0-1','1-2','2-3','3-4','4-5','5-6',\n",
    "                        '6-7','7-8','8-9','9-10','10-11','11-12',\n",
    "                        '12-13','13-14','14-15','15-16','16-17','','MTL (µm) =','Var =','SD =','No. =','','Dpar (avg) =','rmr0\\u1D30 ='],\n",
    "                        \"L2\":['','','','','','','','Count',lengths_summary[1],lengths_summary[2],lengths_summary[3],\n",
    "                        lengths_summary[4],lengths_summary[5],lengths_summary[6],lengths_summary[7],lengths_summary[8],\n",
    "                        lengths_summary[9],lengths_summary[10],lengths_summary[11],lengths_summary[12],lengths_summary[13],\n",
    "                        lengths_summary[14],lengths_summary[15],lengths_summary[16],lengths_summary[17],\n",
    "                        '',\"{:.2f}\".format(mtl),\n",
    "                        \"{:.2f}\".format(mtl_var)\n",
    "                        ,\"{:.2f}\".format(mtl_sd),l_no,'',Dpar_lengths_mean,rmr0D_lengths_mean]}) \n",
    "    else:\n",
    "        lengths_binned = pd.DataFrame ({\"L1\":[''],\"L2\":['']})\n",
    "\n",
    "    #combine the above dataframes horizontally (stack)\n",
    "    single_grain_data = pd.concat([single_grain_header, single_grain_body, single_grain_footer], axis=0)\n",
    "    #add the length bins to the right side\n",
    "    single_grain_data = pd.concat([single_grain_data.reset_index(drop=1),lengths_binned.reset_index(drop=1)], axis=1).fillna('')\n",
    "\n",
    "    #export a csv of summary body only data for possible later use\n",
    "    single_grain_sim = single_grain_body\n",
    "    single_grain_sim = single_grain_sim[[\"col0\",\"col1\",\"col2\",\"col3\",\"col4\",\"col6\",\n",
    "                                         \"col7\",\"col9\",\"col10\",\"col12\",\"col13\",\"col15\",\n",
    "                                         \"col16\",\"col18\",\"col19\",\"col20\",\"col21\",\"col22\"]] #use only these, omit ± cols.\n",
    "    single_grain_sim.columns = [\"grain\",\"ns\",\"area\",\"ps\",\"uppm\",\"uppm_sd\",\"thppm\",\"thppm_sd\",\"euppm\",\n",
    "                                \"euppm_sd\",\"age\",\"age_sd\",\"dpar\",\"dpar_se\",\"rmr0\",\"rmr0D\",\"cl_wt\",\"eCl\"]\n",
    "    single_grain_sim = pd.DataFrame(single_grain_sim)\n",
    "    single_grain_sim.reset_index(drop=True, inplace=True)\n",
    "    single_grain_sim.loc[0,'sample_no'] = sample_name \n",
    "    single_grain_sim.loc[0,'central_age'] = Central_age \n",
    "    single_grain_sim.loc[0,'central_age_sd'] = Central_age_1sigma\n",
    "    single_grain_sim.loc[0,'pooled_age'] = Pooled_age \n",
    "    single_grain_sim.loc[0,'pooled_age_sd'] = Pooled_age_1sigma\n",
    "    single_grain_sim.loc[0,'chi_2'] = X2\n",
    "    single_grain_sim.loc[0,'pchi'] = PX2_perc \n",
    "    single_grain_sim.loc[0,'dispersion'] = Dispersion\n",
    "    single_grain_sim.to_csv('{0}/{1}_age_summary.csv'.format(save_to, sample_name), index=None)\n",
    "\n",
    "    #export a csv of summary of lengths data for possible later use\n",
    "    if mtl != '--':\n",
    "        lengths_sim = lengths_data[[\"Length Name\", \"True Length\"]]\n",
    "        lengths_sim.columns = [\"length_no\",\"true_length\"]\n",
    "        lengths_sim = pd.DataFrame(lengths_sim)\n",
    "        lengths_sim.reset_index(drop=True, inplace=True)\n",
    "        lengths_sim['dpar_avg'] = Dpar_lengths\n",
    "        lengths_sim['rmr0'] = rmr0D_lengths\n",
    "        lengths_sim.to_csv('{0}/{1}_lengths_summary.csv'.format(save_to, sample_name), index=None)\n",
    "    ###############################################################################################################\n",
    "    #Create variables table\n",
    "    variables_table = pd.DataFrame({'Variable':[\"M[238U]\",\"N₀\",\"d(Ap)\",\"R(Ap)\",\"q(Ap)\",\"λd\",\"λf\",\"____\",\"ξ\"],\n",
    "                                   'Value':[M238U,No,dAp,\"{:.3e}\".format(RAp),qAp,ld,lf,\"\",\"{:.4e}\".format(Xi)],\n",
    "                                    'Unit':[\"g/mol\",\"—\",\"g/cm^3\",\"g/cm^3\",\"—\",\"1/t\",\"1/t\",\"\",\"tcm^2\"],\n",
    "                                    'Comment':[\"Molar Mass 238U\",\"Avogadros No.\",\n",
    "                                              \"Density of apatite. derived from a calculated relationship between density and apatite Cl content based on the analyses and unit cell dimensions of Carlson et al. (1999)\",\n",
    "                                              \"Based on half the confined track length for spontaneous tracks apatites (7.5 for volcanic apatites, see (Gleadow et al., 1986); 7.17 average of Durango).\",\n",
    "                                              \"The relatively few direct measurements of this efficiency factor range from 0.90–0.99 (e.g. Iwano et al., 1993; Jonckheere and Van den haute, 2002). Hasebe et al. (2004) used a value of 1.0. Clearly more experimental work is needed to define this parameter with the counting setup used, but for this discussion a value of 0.96 is used.\",\n",
    "                                              \"λd\",\n",
    "                                              \"Spontaneous fission decay constant, value from Yoshioka et al. (2005)\",\n",
    "                                              \"\",\"Aggregate factor = M238U/(λf*N₀*dAp*RAp*qAp)\"]})\n",
    "\n",
    "    ###########################################################\n",
    "    #Combine all above into 1 xlsx file with multiple sheets \n",
    "    writer = pd.ExcelWriter('{0}/{1}_Summary.xlsx'.format(save_to, sample_name),  \n",
    "                              engine ='xlsxwriter',options={'strings_to_urls': False, \n",
    "                                     'strings_to_formulas': False})\n",
    "    single_grain_data.to_excel(writer, sheet_name ='Ages', header = False, index = False)\n",
    "    #ns_df_removed.loc[no_grains+100,'U_ppm_m238'] = \"Copy/paste to retrieve:\"\n",
    "    #ns_df_removed.loc[no_grains+100,'Notes'] = str(remove_grs)\n",
    "    ns_df_removed.to_excel(writer, sheet_name ='Removed_Grains', header = True, index = False)\n",
    "    variables_table.to_excel(writer, sheet_name ='Variables', header = True, index = False)\n",
    "    single_grain_sim.to_excel(writer, sheet_name ='Single_Grain_Body', header = True, index = False)\n",
    "    counts_data.to_excel(writer, sheet_name ='Raw_Count_Data', header = True, index = False)\n",
    "    icpms_data.to_excel(writer, sheet_name ='Raw_ICPMS_Data', header = True, index = False)\n",
    "    if mtl != '--':\n",
    "        lengths_data.to_excel(writer, sheet_name ='Raw_Length_Data', header = True, index = False)\n",
    "\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Ages'] \n",
    "\n",
    "    sci_format = workbook.add_format({'num_format': '0.000E+00'})\n",
    "    format_boldC = workbook.add_format({'bold':  True, 'align': 'center'})\n",
    "    format_boldCTR = workbook.add_format({'bold':  True, 'align': 'center','text_wrap': True})\n",
    "    format_boldL = workbook.add_format({'bold':  True, 'align': 'left'})\n",
    "    format_center = workbook.add_format({'align': 'center'})\n",
    "    format_right = workbook.add_format({'align': 'right'})\n",
    "    format_left = workbook.add_format({'align': 'left'})\n",
    "    format_wrap = workbook.add_format({'align': 'left', 'valign': 'top', 'text_wrap': True})\n",
    "        #modify columns\n",
    "    worksheet.set_column('B:B', 5, cell_format=format_center)#ns\n",
    "    worksheet.set_column('C:D', cell_format=sci_format)#area and rhos\n",
    "    worksheet.set_column('E:E', 6, cell_format=format_right)#Uppm\n",
    "    worksheet.set_column('F:F', 2, cell_format=format_center)#±\n",
    "    worksheet.set_column('G:G', 5, cell_format=format_left)#U ppm sd\n",
    "    worksheet.set_column('H:H', 6, cell_format=format_right)#Thppm\n",
    "    worksheet.set_column('I:I', 2, cell_format=format_center)#±\n",
    "    worksheet.set_column('J:J', 5, cell_format=format_left)#Thppm sd\n",
    "    worksheet.set_column('K:K', 6, cell_format=format_right)#Eu ppm\n",
    "    worksheet.set_column('L:L', 2, cell_format=format_center)#±\n",
    "    worksheet.set_column('M:M', 5, cell_format=format_left)#Euppm sd\n",
    "    worksheet.set_column('N:N', 8, cell_format=format_right)# age\n",
    "    worksheet.set_column('O:O', 2, cell_format=format_center)# ±\n",
    "    worksheet.set_column('P:P', 5, cell_format=format_left)# age sd\n",
    "    worksheet.set_column('Q:Q', 5, cell_format=format_right)# Dpar\n",
    "    worksheet.set_column('R:R', 2, cell_format=format_center)# ±\n",
    "    worksheet.set_column('S:S', 4, cell_format=format_left)#Dpar sd\n",
    "    worksheet.set_column('T:W', 7, cell_format=format_center)#rmr0, rmr0D, CLwt, eCl\n",
    "    worksheet.set_column('X:X', 10, cell_format=format_center)#Length\n",
    "    worksheet.set_column('Y:Y', 8, cell_format=format_center)#Count\n",
    "\n",
    "\n",
    "        #modify rows\n",
    "    worksheet.set_row((0),20, cell_format=format_boldL)\n",
    "    worksheet.set_row((1), cell_format=format_left)\n",
    "    worksheet.set_row((2), cell_format=format_left)\n",
    "    worksheet.set_row((3), cell_format=format_left)\n",
    "    worksheet.set_row((4), cell_format=format_left)\n",
    "    worksheet.set_row((5), cell_format=format_left)\n",
    "    worksheet.set_row((6), cell_format=format_left)\n",
    "    worksheet.set_row((7), 28, cell_format=format_boldCTR)\n",
    "    worksheet.set_row((no_grains+9), 20, cell_format=format_boldC)\n",
    "    worksheet.set_row((no_grains+12), cell_format=format_boldC)\n",
    "    worksheet.set_row((no_grains+13), cell_format=format_boldC)\n",
    "    worksheet.set_row((no_grains+14), cell_format=format_boldC)\n",
    "\n",
    "    workbook2 = writer.book\n",
    "    worksheet2 = writer.sheets['Variables'] \n",
    "    format_wrap2 = workbook2.add_format({'align': 'left', 'valign': 'top', 'text_wrap': True})\n",
    "    worksheet2.set_column('D:D', 100, cell_format=format_wrap2)\n",
    "\n",
    "    workbook3 = writer.book\n",
    "    worksheet3 = writer.sheets['Raw_Count_Data'] \n",
    "    format_wrap3 = workbook3.add_format({'align': 'left', 'valign': 'top', 'text_wrap': True})\n",
    "    worksheet3.set_column('G:G', 80, cell_format=format_wrap3)\n",
    "    writer.save()\n",
    "    ###############################################################################################################\n",
    "    #create a csv that will append pooled data, this will append new data (ie: next sample) as a new row so you can use the bulk data in other programs\n",
    "    append_pooled_data = pd.DataFrame({\"date_created\":datetime.now().strftime(\"%H:%M:%S %d/%m/%Y\"),\n",
    "                                        \"sample_name\":[sample_name],\n",
    "                                       \"igsn\":[igsn],\n",
    "                                       \"collector\":[collector],\n",
    "                                       \"analyst\":[analyst],\n",
    "                                       \"mineral\":[mineral],\n",
    "                                       \"rock_type\":[rock_type],\n",
    "                                       \"country\":[country],\n",
    "                                       \"region\":[region],\n",
    "                                       \"latitude\":[latitude],\n",
    "                                       \"longitude\":[longitude],\n",
    "                                       \"elevation_m\":[elevation],\n",
    "                                       \"Ustandard\":[Ustandard],\n",
    "                                       \"IntU_standard\":[Intstandard],\n",
    "                                       \"IntU_mean\":[mean_intstd],\n",
    "                                       \"IntU_sd\":[meanerr_intstd],\n",
    "                                       \"spot_size\":[spot_size],\n",
    "                                       \"lab_name\":[lab_name],\n",
    "                                       \"etchant\":[etchant],\n",
    "                                       \"etching_time\":[etching_time],\n",
    "                                       \"etching_temp\":[etching_temp],\n",
    "                                       \"Xi\":[round(Xi, 7)],\n",
    "                                       \"grains_tot\":[ns.count()],\n",
    "                                       \"ns_tot\":[np.sum(ns).astype(int)],\n",
    "                                       \"area_tot\":[round(np.sum(area),10)],\n",
    "                                       \"ps_mean\":[round(np.mean(ps),2)],\n",
    "                                       \"uppm_mean\":[round(np.mean(U_ppm),2)],\n",
    "                                       \"uppm_sdm\":[round(np.std(U_ppm), 2)],\n",
    "                                       \"thppm_mean\":[round(np.mean(Th_ppm),2)],\n",
    "                                       \"thppm_sdm\":[round(np.std(Th_ppm), 2)],\n",
    "                                       \"euppm_mean\":[round(np.mean(eU), 2)],\n",
    "                                       \"euppm_sdm\":[round(np.std(eU), 2)],\n",
    "                                       \"page\":[round(Pooled_age, 2)],\n",
    "                                       \"page_sd\":[round(Pooled_age_1sigma, 2)],\n",
    "                                       \"cage\":[round(Central_age, 2)],\n",
    "                                       \"cage_sd\":[round(Central_age_1sigma, 2)],\n",
    "                                       \"X2\":[round(X2, 2)],\n",
    "                                       \"PX2\":[round(PX2_perc, 2)],\n",
    "                                       \"dispersion\":[round(Dispersion, 2)],\n",
    "                                       \"dpar_mean\":[round(np.mean(Dpar), 2)],\n",
    "                                       \"dpar_sdm\":[round(np.std(Dpar), 2)],\n",
    "                                       \"cl_wt_mean\":[np.where(Cl_sem_mean == '--', '', Cl_sem_mean)],\n",
    "                                       \"cl_sdm\":[np.where(Cl_sem_sdm == '--', '', Cl_sem_sdm)],\n",
    "                                       \"rmr0_mean\":[np.where(rmr0_mean == '--', '', rmr0_mean)],\n",
    "                                       \"rmr0_sdm\":[np.where(rmr0_sdm == '--', '', rmr0_sdm)],\n",
    "                                       \"rmr0D_mean\":[np.where(rmr0D_mean == '--', '', rmr0D_mean)],\n",
    "                                       \"rmr0D_sdm\":[np.where(rmr0D_sdm == '--', '', rmr0D_sdm)],\n",
    "                                       \"len_no\":[np.where(l_no == '--', '', l_no)],\n",
    "                                       \"mtl\":[np.where(mtl == '--', '', mtl)],\n",
    "                                       \"mtl_var\":[np.where(mtl_var == '--', '', mtl_var)],\n",
    "                                       \"mtl_sd\":[np.where(mtl_sd == '--', '', mtl_sd)],\n",
    "                                       \"mtl_dpar_mean\":[Dpar_lengths_mean],\n",
    "                                       \"rmr0D_length_mean\":[rmr0D_lengths_mean],\n",
    "                                       \"rmr0D_length_sdm\":[rmr0D_lengths_sdm],\n",
    "                                       \"eCl_mean\":[np.where(eCL_mean == '--', '', eCL_mean)],\n",
    "                                       \"eCl_sdm\":[np.where(eCL_sdm == '--', '', eCL_sdm)]})\n",
    "\n",
    "    up_onefolder = str(Path(save_to).parents[0])\n",
    "    append_filepath = Path('{0}/pooled_age_summary.csv'.format(up_onefolder))\n",
    "\n",
    "    if append_filepath.exists():\n",
    "        append_pooled_df = pd.read_csv('{0}/pooled_age_summary.csv'.format(up_onefolder)) \n",
    "        append_pooled_df.drop(append_pooled_df[append_pooled_df['sample_name'] == sample_name].index,\n",
    "                              inplace=True, errors='raise')\n",
    "        append_pooled_df.to_csv('{0}/pooled_age_summary.csv'.format(up_onefolder), header=True, index=None)\n",
    "        append_pooled_data.to_csv('{0}/pooled_age_summary.csv'.format(up_onefolder), mode='a', header=False, index=None)\n",
    "    else:\n",
    "        append_pooled_data.to_csv('{0}/pooled_age_summary.csv'.format(up_onefolder), header=True, index=None)\n",
    "    ###############################################################################################################\n",
    "    #create and export tables for use in various programs\n",
    "        #create a folder to store these\n",
    "    data_folder = '{0}/Data_Import'.format(save_to)\n",
    "    if not os.path.exists(data_folder): os.makedirs(data_folder)\n",
    "    #export tables to use in HeFty\n",
    "        #Age File:\n",
    "        ###using dpar\n",
    "    hefty_age_header = pd.DataFrame({sample_name:[\"Zeta:\",\"zeta\",\"4352.32\",\"Ns\"],\n",
    "                                    \"col1\":[\"LAICPMS ratio\",\"sig zeta\",\"1.1\",\"Area (cm²)\"],\n",
    "                                    \"col2\":[\"\",\"\",\"\",\"Pcorr\"],\n",
    "                                    \"col3\":[\"\",\"\",\"\",\"sig(Pcorr)\"],\n",
    "                                    \"col4\":[\"\",\"\",\"\",\"Dpar\"]})   \n",
    "    hefty_age_data = pd.DataFrame({sample_name:ns,\n",
    "                                     \"col1\":area,\n",
    "                                     \"col2\":U_ppm,\n",
    "                                     \"col3\":U_ppm_1sigma,\n",
    "                                     \"col4\":Dpar}) \n",
    "    hefty_age_data = hefty_age_data.replace({\"col4\":{np.nan:Dpar_mean}}) \n",
    "    hefty_age = pd.concat([hefty_age_header, hefty_age_data], axis=0)\n",
    "    hefty_age.to_csv(r'{0}/{1}_HeftyAGE(Dpar).txt'.format(data_folder, sample_name), na_rep=0, index=None, sep='\\t')\n",
    "            ###using rmr0\n",
    "    if 'rmr0' in age_df.columns:\n",
    "        hefty_age_header_rmr0 = pd.DataFrame({sample_name:[\"Zeta:\",\"zeta\",\"4352.32\",\"Ns\"],\n",
    "                                    \"col1\":[\"LAICPMS ratio\",\"sig zeta\",\"1.1\",\"Area (cm²)\"],\n",
    "                                    \"col2\":[\"\",\"\",\"\",\"Pcorr\"],\n",
    "                                    \"col3\":[\"\",\"\",\"\",\"sig(Pcorr)\"],\n",
    "                                    \"col4\":[\"\",\"\",\"\",\"rmr0\"]})   \n",
    "        hefty_age_data_rmr0 = pd.DataFrame({sample_name:ns,\n",
    "                                     \"col1\":area,\n",
    "                                     \"col2\":U_ppm,\n",
    "                                     \"col3\":U_ppm_1sigma,\n",
    "                                     \"col4\":rmr0}) \n",
    "        hefty_age_data_rmr0 = hefty_age_data_rmr0.replace({\"col4\":{np.nan:rmr0_mean}}) \n",
    "        hefty_age_rmr0 = pd.concat([hefty_age_header_rmr0, hefty_age_data_rmr0], axis=0)\n",
    "        hefty_age_rmr0.to_csv(r'{0}/{1}_HeftyAGE(rmr0).txt'.format(data_folder, sample_name), na_rep=0, index=None, sep='\\t')\n",
    "\n",
    "    ################################\n",
    "        #Length File:\n",
    "    if mtl != '--':\n",
    "        hefty_length = pd.DataFrame({\"length\":lengths_data['True Length'],\n",
    "                    \"angle\":lengths_data['Angle to CAxis'],\"Dpar\":lengths_data['Average DPar(µmm)']})\n",
    "        hefty_length = hefty_length.replace({\"Dpar\":{np.nan:np.mean(lengths_data['Average DPar(µmm)'])}})\n",
    "        hefty_length.to_csv(r'{0}/{1}_HeftyLENGTH(Dpar).txt'.format(data_folder, sample_name), na_rep=0, index=None, sep='\\t')\n",
    "    \n",
    "    if mtl != '--':\n",
    "        hefty_length_rmr0 = pd.DataFrame({\"length\":lengths_data['True Length'],\n",
    "                    \"angle\":lengths_data['Angle to CAxis'],\"rmr0\":rmr0D_lengths})\n",
    "        hefty_length_rmr0 =  hefty_length_rmr0.replace({\"rmr0\":{np.nan:np.mean(rmr0D_lengths)}})\n",
    "        hefty_length_rmr0.to_csv(r'{0}/{1}_HeftyLENGTH(rmr0).txt'.format(data_folder, sample_name), na_rep=0, index=None, sep='\\t')\n",
    "\n",
    "    ###############################################################################################################\n",
    "    #export tables to use in RadialPlotter\n",
    "    \n",
    "        #ColorwUppm:\n",
    "    radialplotter_U = pd.DataFrame({sample_name:Age_sga.round(2),\"O\":Age_sga_1sigma.round(2),\"\":U_ppm.round(2)})\n",
    "    radialU_path = '{0}/{1}_Radial_U.csv'.format(data_folder, sample_name)\n",
    "    radialplotter_U.to_csv(r'{0}'.format(radialU_path), na_rep=0, index=None)\n",
    "    \n",
    "        #ColorwDpar:\n",
    "    radialplotter_Dpar = pd.DataFrame({sample_name:Age_sga.round(2),\"O\":Age_sga_1sigma.round(2),\"\":Dpar.round(2)})\n",
    "    radialplotter_Dpar = radialplotter_Dpar.replace({\"\":{np.nan:round(np.mean(Dpar), 3)}})\n",
    "    radialDpar_path = '{0}/{1}_Radial_Dpar.csv'.format(data_folder, sample_name)\n",
    "    radialplotter_Dpar.to_csv(r'{0}'.format(radialDpar_path), na_rep=0, index=None)\n",
    "    \n",
    "        #Colorw rmr0 calculated from Dpar\n",
    "    radialplotter_rmr0D = pd.DataFrame({sample_name:Age_sga.round(2),\"O\":Age_sga_1sigma.round(2),\"\":rmr0D})\n",
    "    radialplotter_rmr0D =  radialplotter_rmr0D.replace({\"\":{np.nan:round(np.mean(rmr0D), 3)}})\n",
    "    radialrmr0D_path = '{0}/{1}_Radial_rmr0(From_Dpar).csv'.format(data_folder, sample_name)\n",
    "    radialplotter_rmr0D.to_csv(r'{0}'.format(radialrmr0D_path), na_rep=0, index=None)\n",
    "       \n",
    "        #ColorwCl (if cl is there)\n",
    "    if np.issubdtype(ns_df['Cl wt (%)'].dtype, np.number):\n",
    "        radialplotter_Cl = pd.DataFrame({sample_name:Age_sga.round(2),\"O\":Age_sga_1sigma.round(2),\"\":Cl_sem})\n",
    "        radialplotter_Cl =  radialplotter_Cl.replace({\"\":{np.nan:round(np.mean(Cl_sem), 3)}})\n",
    "        radialCl_path = '{0}/{1}_Radial_Cl.csv'.format(data_folder, sample_name)\n",
    "        radialplotter_Cl.to_csv(r'{0}'.format(radialCl_path), na_rep=0, index=None)\n",
    "        \n",
    "        #Colorwrmr0 (if rmr0 is there)\n",
    "    if np.issubdtype(ns_df['rmr0'].dtype, np.number):\n",
    "        radialplotter_rmr0 = pd.DataFrame({sample_name:Age_sga.round(2),\"O\":Age_sga_1sigma.round(2),\"\":rmr0})\n",
    "        radialplotter_rmr0 =  radialplotter_rmr0.replace({\"\":{np.nan:round(np.mean(rmr0), 3)}})\n",
    "        radialrmr0_path = '{0}/{1}_Radial_rmr0.csv'.format(data_folder, sample_name)\n",
    "        radialplotter_rmr0.to_csv(r'{0}'.format(radialrmr0_path), na_rep=0, index=None)\n",
    "    ###############################################################################################################\n",
    "    #export tables to use in QTQT (must copy and paste into QTQT)\n",
    "        #age\n",
    "    if 'rmr0' in age_df.columns:\n",
    "        qtqt_age = pd.DataFrame({'Sample:{0}\\n Ns'.format(sample_name): ns,\"ICPMS_Age\":Age_sga.round(2),\n",
    "                              \"ICPMS_Age 1Sigma\":Age_sga_1sigma.round(2),\"Dpar\":Dpar.round(2),\"Cl\":Cl_sem,\"rmr0\":rmr0})\n",
    "        qtqt_age = qtqt_age.replace({\"Dpar\":{np.nan:round(np.mean(Dpar), 2)}})\n",
    "        qtqt_age = qtqt_age.replace({\"Cl\":{np.nan:round(np.mean(Cl_sem), 3)}})\n",
    "        qtqt_age = qtqt_age.replace({\"rmr0\":{np.nan:round(np.mean(rmr0), 3)}})\n",
    "        qtqt_age.to_csv(r'{0}/{1}_QTQT_age.csv'.format(data_folder, sample_name), na_rep=0, index=None)\n",
    "    else:\n",
    "        qtqt_age = pd.DataFrame({'Sample:{0}\\n Ns'.format(sample_name): ns,\"ICPMS_Age\":Age_sga.round(2),\n",
    "                              \"ICPMS_Age 1Sigma\":Age_sga_1sigma.round(2),\"Dpar\":Dpar.round(2),\"Cl\":Cl_sem,\"rmr0\":rmr0D})\n",
    "        qtqt_age = qtqt_age.replace({\"Dpar\":{np.nan:round(np.mean(Dpar), 2)}})\n",
    "        qtqt_age = qtqt_age.replace({\"rmr0\":{np.nan:round(np.mean(rmr0D), 3)}})\n",
    "        qtqt_age.to_csv(r'{0}/{1}_QTQT_age.csv'.format(data_folder, sample_name), na_rep=0, index=None)\n",
    "\n",
    "        #length\n",
    "    if mtl != '--':\n",
    "        qtqt_length = pd.DataFrame({'Sample:{0}\\n Length'.format(sample_name): lengths_data['True Length'],\"Angle to C\":lengths_data['Angle to CAxis'],\n",
    "                              \"Dpar\":lengths_data['Average DPar(µmm)'],\"rmr0_Dpar\":rmr0D_lengths})\n",
    "        qtqt_length = qtqt_length.replace({\"Dpar\":{np.nan:round(np.mean(lengths_data['Average DPar(µmm)']),2)}})\n",
    "        qtqt_length = qtqt_length.replace({\"rmr0_Dpar\":{np.nan:round(np.mean(rmr0D_lengths), 3)}})\n",
    "        qtqt_length.to_csv(r'{0}/{1}_QTQT_length.csv'.format(data_folder, sample_name), na_rep=0, index=None)\n",
    "    ###############################################################################################################\n",
    "    #export table to use in IsoplotR\n",
    "    isoplot_r = pd.DataFrame({'Sample:{0}\\n Ns'.format(sample_name): ns,\"A(µm2)\":(area*10**8).round(0),\n",
    "                              \"U1(ppm)\":U_ppm.round(2),\"err[U1]\":U_ppm_1sigma.round(2)})\n",
    "    isoplot_r.to_csv(r'{0}/{1}_IsoplotR.csv'.format(data_folder, sample_name), na_rep=0, index=None)\n",
    "    ###############################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_data = 1\n",
    "# if map_data != 0:\n",
    "#     def map_sample(b):\n",
    "#         display(Javascript('IPython.notebook.execute_cell()'))\n",
    "#         fig = plt.figure(constrained_layout=True, figsize=(15,10),)\n",
    "#         spec = gs.GridSpec(ncols=1, nrows=1, figure=fig)\n",
    "#\n",
    "#         ax = fig.add_subplot(spec[0, 0])\n",
    "#         map = Basemap(llcrnrlon=append_pooled_df['longitude'].min()-0.5,llcrnrlat=append_pooled_df['latitude'].min()-0.5,\n",
    "#                       urcrnrlon=append_pooled_df['longitude'].max()+0.5,urcrnrlat=append_pooled_df['latitude'].max()+0.5,\n",
    "#                       ax=ax, resolution='l',epsg=4326)\n",
    "#\n",
    "#         map.arcgisimage(service='ESRI_Imagery_World_2D', xpixels = 400, verbose= True)\n",
    "#         map.drawcountries(color='k')\n",
    "#         map.scatter(append_pooled_df['longitude'], append_pooled_df['latitude'], latlon=True,\n",
    "#               color='r', s=10,alpha=0.8, label=\"Other Samples\")\n",
    "#         map.scatter(longitude, latitude, latlon=True,\n",
    "#               color='#e0c200', s=20, alpha=0.8, label=\"This Sample\")\n",
    "#         ax.annotate(round(Central_age,1),(longitude+0.01,latitude+0.01),\n",
    "#                        fontsize=10,\n",
    "#                        color='#e0c200')\n",
    "#         for i, txt in enumerate(append_pooled_df['cage']):\n",
    "#             ax.annotate(append_pooled_df['cage'][i],\n",
    "#                         (append_pooled_df['longitude'][i]+0.01,append_pooled_df['latitude'][i]+0.01),\n",
    "#                        fontsize=10,\n",
    "#                        color='r')\n",
    "#         ax.legend(loc='upper right')\n",
    "#\n",
    "#         #ax.text(longitude+0.02, latitude+0.02, sample_name,\n",
    "#         #      color='#e0c200',alpha=0.8, fontsize=16, weight='bold')\n",
    "#\n",
    "#     map_loc = widgets.Button(description = \"Map All Sample Locations\",button_style='success')\n",
    "#     map_loc.on_click(map_sample)\n",
    "#\n",
    "#\n",
    "# display(map_loc)\n",
    "# print(\"Might Take a Minute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    print('Done', date.today())\n",
    "    display(ns_df.style.hide_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    print('7) OPTIONAL: PATH TO RADIAL PLOTTER .JAR FILE')\n",
    "    radial_plotter_w = widgets.Text(\n",
    "        value='RadialPlotter.jar',\n",
    "        placeholder='/Users/Desktop/RadialPlotter.jar',\n",
    "        description='Radial .jar:',\n",
    "        layout=Layout(width='90%', height='100%'),\n",
    "        disabled=False)\n",
    "\n",
    "    def clear_rfolder(b):\n",
    "        radial_plotter_w.value = \"\"\n",
    "    clear_rbutton = widgets.Button(description = \"Clear Path\", button_style='danger')\n",
    "    clear_rbutton.on_click(clear_rfolder)\n",
    "\n",
    "\n",
    "    display(widgets.VBox([widgets.HBox([radial_plotter_w]),widgets.HBox([clear_rbutton])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    print('7.1) Open Radial Plotter to save certain settings, separate from those below\\n    (colors, transformation type, Z label)\\n')\n",
    "\n",
    "    def radial_settings(b):\n",
    "        subprocess.call(['java', '-jar', radial_plotter_w.value,\n",
    "                         'in='])\n",
    "\n",
    "    rsettings_button = widgets.Button(description = \"Radial Plotter Settings\", button_style='primary',\n",
    "                                      layout=Layout(width='47%'))\n",
    "    rsettings_button.on_click(radial_settings)\n",
    "\n",
    "\n",
    "    display(widgets.HBox([rsettings_button]))\n",
    "    print('--Change settings, then close the window and continue--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    print('7.2) Plot based on the variable for the color\\n')\n",
    "    print('-->only # of mixture models is variable here,\\n to change colors, transformation or Z label, use\\n \"Radial Plotter Settings button above\"<--')\n",
    "\n",
    "\n",
    "    #middle mixture models\n",
    "    mixture_w = widgets.Select(\n",
    "        options=[('0 Mix. Model', 0), ('1 Mix. Model', 1),( '2 Mix. Model', 2),\n",
    "                 ('3 Mix .Model', 3), ('4 Mix. Model', 4),\n",
    "                ('5 Mix. Model', 5)],\n",
    "        layout=Layout(flex='1 1 auto', width='auto'),\n",
    "        value=0,\n",
    "        rows=6,\n",
    "        #description='OS:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "\n",
    "    #right side image\n",
    "    ex_img = open('example.jpg', 'rb').read()\n",
    "    ex_im_w = widgets.Image(value=ex_img, format='jpg', \n",
    "                            layout=Layout(flex='2 1 auto', width='auto'),\n",
    "                            width=200)\n",
    "\n",
    "    #left side\n",
    "    #Dpar\n",
    "    def color_dpar(b):\n",
    "        radial_folder = '{0}/Radial_Plots'.format(up_onefolder)\n",
    "        if not os.path.exists(radial_folder): os.makedirs(radial_folder)\n",
    "\n",
    "        subprocess.call(['java', '-jar', radial_plotter_w.value,\n",
    "                         'numpeaks={}'.format(mixture_w.value),\n",
    "                         'in={}'.format(radialDpar_path),\n",
    "                        'out={0}/{1}_Dpar{2}mix.pdf'.format(radial_folder,sample_name,mixture_w.value)])\n",
    "        with out_dpar:\n",
    "            print('File saved to:',radial_folder)\n",
    "\n",
    "\n",
    "\n",
    "    #U ppm\n",
    "    def color_U(b):\n",
    "        radial_folder = '{0}/Radial_Plots'.format(up_onefolder)\n",
    "        if not os.path.exists(radial_folder): os.makedirs(radial_folder)\n",
    "\n",
    "        subprocess.call(['java', '-jar', radial_plotter_w.value,\n",
    "                         'numpeaks={}'.format(mixture_w.value),\n",
    "                         'in={}'.format(radialU_path),\n",
    "                        'out={0}/{1}_U{2}mix.pdf'.format(radial_folder,sample_name,mixture_w.value)])\n",
    "        with out_U:\n",
    "            print('File saved to:',radial_folder)\n",
    "\n",
    "\n",
    "\n",
    "    if 'rmr0' in age_df.columns:\n",
    "        #Cl wt%\n",
    "        def color_Cl(b):\n",
    "            radial_folder = '{0}/Radial_Plots'.format(up_onefolder)\n",
    "            if not os.path.exists(radial_folder): os.makedirs(radial_folder)\n",
    "\n",
    "            subprocess.call(['java', '-jar', radial_plotter_w.value,\n",
    "                             'numpeaks={}'.format(mixture_w.value),\n",
    "                             'in={}'.format(radialCl_path),\n",
    "                            'out={0}/{1}_Cl{2}mix.pdf'.format(radial_folder,sample_name,mixture_w.value)])\n",
    "            with out_Cl:\n",
    "                print('File saved to:',radial_folder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #rmr0\n",
    "        def color_rmr0(b):\n",
    "            radial_folder = '{0}/Radial_Plots'.format(up_onefolder)\n",
    "            if not os.path.exists(radial_folder): os.makedirs(radial_folder)\n",
    "\n",
    "            subprocess.call(['java', '-jar', radial_plotter_w.value,\n",
    "                             'numpeaks={}'.format(mixture_w.value),\n",
    "                             'in={}'.format(radialrmr0_path),\n",
    "                            'out={0}/{1}_rmr0{2}mix.pdf'.format(radial_folder,sample_name,mixture_w.value)])\n",
    "            with out_rmr0:\n",
    "                print('File saved to:',radial_folder)\n",
    "\n",
    "        color_Cl_button = widgets.Button(description = \"Plot with wt% Cl\", button_style='',\n",
    "                                         layout=Layout(flex='2 1 auto', width='auto'))\n",
    "\n",
    "        color_rmr0_button = widgets.Button(description = \"Plot with rmr0\", button_style='',\n",
    "                                         layout=Layout(flex='2 1 auto', width='auto'))\n",
    "        \n",
    "        color_dpar_button = widgets.Button(description = \"Plot with Dpar\", button_style='',\n",
    "                                         layout=Layout(flex='2 1 auto', width='auto'))\n",
    "\n",
    "        color_U_button = widgets.Button(description = \"Plot with [U]\", button_style='',\n",
    "                                          layout=Layout(flex='2 1 auto', width='auto'))\n",
    "\n",
    "        color_Cl_button.on_click(color_Cl)\n",
    "        out_Cl = Output()\n",
    "\n",
    "        color_rmr0_button.on_click(color_rmr0)\n",
    "        out_rmr0 = Output()\n",
    "        \n",
    "        color_dpar_button.on_click(color_dpar)\n",
    "        out_dpar = Output()\n",
    "\n",
    "        color_U_button.on_click(color_U)\n",
    "        out_U = Output()\n",
    "\n",
    "        items_2 = [Label('Select Composition'),\n",
    "               color_dpar_button, color_U_button, color_Cl_button, color_rmr0_button]\n",
    "        items_4 = [out_dpar, out_U, out_Cl, out_rmr0]\n",
    "\n",
    "    else:\n",
    "        color_dpar_button = widgets.Button(description = \"Plot with Dpar\", button_style='',\n",
    "                                         layout=Layout(flex='2 1 auto', width='auto'))\n",
    "\n",
    "        color_U_button = widgets.Button(description = \"Plot with [U]\", button_style='',\n",
    "                                          layout=Layout(flex='2 1 auto', width='auto'))\n",
    "        \n",
    "        color_dpar_button.on_click(color_dpar)\n",
    "        out_dpar = Output()\n",
    "\n",
    "        color_U_button.on_click(color_U)\n",
    "        out_U = Output()\n",
    "    \n",
    "        \n",
    "        items_2 = [Label('Select Composition'),\n",
    "                   color_dpar_button, color_U_button]\n",
    "        items_4 = [out_dpar, out_U]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    items_1 = [Label('# of Mixture Models'),mixture_w]\n",
    "    items_3 = [Label('Ex. plot w/ 2 mixture models, color w/ Dpar'),ex_im_w]\n",
    "\n",
    "    box_layout = Layout(display='flex',\n",
    "                        flex_flow='column',\n",
    "                        align_items='stretch',\n",
    "                        width='30%')\n",
    "    box_layout2 = Layout(display='flex',\n",
    "                        flex_flow='column',\n",
    "                        align_items='stretch',\n",
    "                        width='15%')\n",
    "\n",
    "    box_1 = Box(children=items_1, layout=box_layout2)\n",
    "    box_2 = Box(children=items_2, layout=box_layout)\n",
    "    box_3 = Box(children=items_3, layout=box_layout)\n",
    "    box_4 = Box(children=items_4, layout=box_layout)\n",
    "\n",
    "    display(VBox([(HBox([box_1, box_2, box_3])),(HBox([box_4]))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:\n",
    "    if mtl != '--':\n",
    "        def histograms(b):\n",
    "            mtl_folder = '{0}/Histograms'.format(up_onefolder)\n",
    "            if not os.path.exists(mtl_folder): os.makedirs(mtl_folder)\n",
    "\n",
    "            bins_c = color_Bins_w.value\n",
    "            stroke_c = color_Stroke_w.value\n",
    "            KDE_c = color_KDE_w.value\n",
    "            bins = bins_w.value\n",
    "            histtype = bins_type_w.value\n",
    "            #first figure; large, easy to read, with all data. Good for appendix\n",
    "            fig1 = plt.figure(constrained_layout=False, figsize=(3,3))\n",
    "            spec = gs.GridSpec(nrows=1,ncols=1, figure=fig1)\n",
    "            ax = plt.subplot(spec[0,0])\n",
    "            ax.hist(true_length, bins=bins, range=(2,17),  histtype=histtype, \n",
    "                    facecolor=bins_c,edgecolor=stroke_c, linewidth=1.5, alpha=0.8)\n",
    "                #Creating another Y axis\n",
    "            second_ax = ax.twinx()\n",
    "                #Plotting kde without hist on the second Y axis\n",
    "            if KDE_w.value ==1:\n",
    "                sns.kdeplot(true_length, ax=second_ax, color=KDE_c, linewidth=3, alpha=0.8)\n",
    "            ax.axvline(mtl, linewidth=1.5, linestyle='--', color='k', alpha=0.7, label='MTL')\n",
    "            ax.text(0.015, 0.985, 'MTL = {0:.1f}±{1:.1f} µm\\nSD = {2:.1f} µm\\nN = {3}' .format(mtl, mtl_var, mtl_sd, l_no),\n",
    "                         horizontalalignment='left',verticalalignment='top', transform=ax.transAxes, fontsize=10)\n",
    "            ax.set_ylabel('Count', fontsize=11)\n",
    "            second_ax.set_ylabel('Relative Frequency', fontsize=11)\n",
    "            ax.set_xlabel('Track Length (µm)', fontsize=11)\n",
    "            ax.tick_params(axis=\"x\", labelsize=10)\n",
    "            ax.tick_params(axis=\"y\", labelsize=10)\n",
    "            ax.autoscale(enable=True, axis='x', tight=True)\n",
    "            ax.set_xticks(ticks=[2,4,6,8,10,12,14,16], minor=False)\n",
    "            ax.set_yticks(ticks=[0,10,20,30,40,50], minor=False)\n",
    "            ax.set_ylim([0,50])\n",
    "            second_ax.set_ylim([0,0.5])\n",
    "            ax.set_xlim([2,17])\n",
    "            ax.set_title(\"{0}\".format(sample_name), fontdict={'fontsize': \"11\"}, loc='left')\n",
    "\n",
    "\n",
    "                #2nd histogram plot, smaller and good for maps/used in other plots\n",
    "            fig2 = plt.figure(constrained_layout=False, figsize=(1.3,1.3))\n",
    "            spec = gs.GridSpec(nrows=1,ncols=1, figure=fig2)\n",
    "            ax2 = plt.subplot(spec[0,0])\n",
    "            ax2.hist(true_length, bins=bins, range=(2,17), histtype=histtype,\n",
    "                             facecolor=bins_c,edgecolor=stroke_c, linewidth=0.8, alpha=0.8)\n",
    "                #Creating another Y axis\n",
    "            second_ax2 = ax2.twinx()\n",
    "                #Plotting kde without hist on the second Y axis\n",
    "            if KDE_w.value ==1:\n",
    "                sns.kdeplot(true_length, ax=second_ax2, color=KDE_c, linewidth= 1.5, alpha=0.8)\n",
    "            sns.despine(fig=None, ax=second_ax2, top=True, right=True, left=False, bottom=False, offset=None, trim=False)\n",
    "                #Removing Y ticks from the second axis\n",
    "            second_ax2.set_yticks([])\n",
    "            second_ax2.get_yaxis().set_visible(False)\n",
    "            ax2.text(0.015, 1.0, '{0}\\nMTL: {1:.1f}±{2:.1f}\\n' .format(sample_name, mtl, mtl_var),\n",
    "                         horizontalalignment='left',verticalalignment='top', transform=ax2.transAxes, fontsize=8)\n",
    "            ax2.set_xticks(ticks=[4,8,12,16], minor=False)\n",
    "            ax2.tick_params(axis=\"x\", labelsize=8)\n",
    "            ax2.tick_params(axis=\"y\", labelsize=8)\n",
    "            ax2.spines['top'].set_visible(False)\n",
    "            ax2.spines['right'].set_visible(False)\n",
    "            ax2.set_ylim([0,50])\n",
    "            second_ax2.set_ylim([0,0.5])\n",
    "            ax2.set_xlim([2,17])\n",
    "\n",
    "                #3rd histogram plot, much much smaller for use in tight maps etc\n",
    "            fig3 = plt.figure(constrained_layout=False, figsize=(0.6,0.6))\n",
    "            spec = gs.GridSpec(nrows=1,ncols=1, figure=fig3)\n",
    "            ax3 = plt.subplot(spec[0,0])\n",
    "            ax3.hist(true_length, bins=bins, range=(2,17), color='grey', alpha=0.6) \n",
    "                #Creating another Y axis\n",
    "            second_ax3 = ax3.twinx()\n",
    "                #Plotting kde without hist on the second Y axis\n",
    "            sns.kdeplot(true_length, ax=second_ax3, color=\"k\", linewidth=1, alpha=1)\n",
    "            sns.despine(fig=None, ax=second_ax3, top=True, right=True, left=True, bottom=True, offset=None, trim=False)\n",
    "                #Removing Y ticks from the second axis\n",
    "            second_ax3.set_yticks([])\n",
    "            second_ax3.get_yaxis().set_visible(False)\n",
    "            ax3.text(0.5, -0.2, '{0:.1f}±{1:.1f}' .format(mtl,mtl_sd),\n",
    "                         horizontalalignment='center',verticalalignment='center', transform=ax3.transAxes, fontsize=9)\n",
    "            ax3.get_xaxis().set_ticks([])\n",
    "            ax3.get_yaxis().set_ticks([])\n",
    "            ax3.set_ylim([0,40])\n",
    "            second_ax3.set_ylim([0,0.4])\n",
    "            ax3.set_xlim([2,17])\n",
    "\n",
    "            with out_mtl:\n",
    "                #plt.show(fig1)\n",
    "                print('File saved to:',mtl_folder)\n",
    "\n",
    "            file_path1 = \"{0}/{1}_l.pdf\".format(mtl_folder,sample_name)\n",
    "            fig1.savefig(file_path1, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            file_path2 = \"{0}/{1}_m.pdf\".format(mtl_folder,sample_name)\n",
    "            fig2.savefig(file_path2, dpi=300, bbox_inches='tight')\n",
    "            plt.close() \n",
    "\n",
    "\n",
    "            file_path3  = \"{0}/{1}_s.pdf\".format(mtl_folder,sample_name)\n",
    "            fig3.savefig(file_path3, dpi=300, bbox_inches='tight')\n",
    "            plt.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if counts_file_w.value != {} or counts_paths != []:    \n",
    "    if mtl != '--':\n",
    "        print(\"8) GENERATE TRACK LENGTH HISTOGRAMS\")\n",
    "\n",
    "        histograms_button = widgets.Button(description = \"Generate TL Histograms\",\n",
    "                                        button_style='primary', layout=Layout(width='47%'))\n",
    "        histograms_button.on_click(histograms)\n",
    "\n",
    "            #example image\n",
    "        mtl_img = open('example_mtl.jpg', 'rb').read()\n",
    "        mtl_im_w = widgets.Image(value=mtl_img, format='jpg', \n",
    "                                    layout=Layout(flex='1 1 auto', width='auto'),\n",
    "                                    width=200)\n",
    "\n",
    "        color_KDE_w = widgets.ColorPicker(\n",
    "            concise=False,\n",
    "            description='KDE Color',\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            value='#6495ED',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        KDE_w = widgets.Select(\n",
    "            options=[(\"On\",1), (\"Off\",0)],\n",
    "            value=1,\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            rows=2,\n",
    "            description='KDE on/off',\n",
    "            disabled=False)\n",
    "\n",
    "\n",
    "        color_Bins_w = widgets.ColorPicker(\n",
    "            concise=False,\n",
    "            description='Bins Color',\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            value='#CCCCCC',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        bins_type_w = widgets.Select(\n",
    "            options=['bar', 'barstacked', 'step', 'stepfilled'],\n",
    "            value='stepfilled',\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            rows=4,\n",
    "            description='Bar Type',\n",
    "            disabled=False)\n",
    "\n",
    "        bins_w = widgets.IntText(\n",
    "            value=15,\n",
    "            description='No. of Bins:',\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            step=1,\n",
    "            disabled=False,)\n",
    "\n",
    "        color_Stroke_w = widgets.ColorPicker(\n",
    "            concise=False,\n",
    "            description='Stroke Color',\n",
    "            layout=Layout(flex='1 1 auto', width='auto'),\n",
    "            value='#000000',\n",
    "            disabled=False\n",
    "        )\n",
    "\n",
    "        out_mtl = Output()\n",
    "\n",
    "\n",
    "        mtlitems_1 = [Label('Example Histogram w Default Colors'),mtl_im_w]\n",
    "        mtlitems_2 = [color_KDE_w,KDE_w,color_Bins_w,bins_type_w,bins_w,color_Stroke_w]\n",
    "        mtlitems_3 = [histograms_button, out_mtl]\n",
    "\n",
    "\n",
    "        mtl_layout = Layout(display='flex',\n",
    "                                flex_flow='column',\n",
    "                                align_items='stretch',\n",
    "                                width='30%')\n",
    "\n",
    "        mtl_layout2 = Layout(display='flex',\n",
    "                                flex_flow='column',\n",
    "                                align_items='stretch',\n",
    "                                width='100%')\n",
    "\n",
    "        mtlbox_1 = Box(children=mtlitems_1, layout=mtl_layout)\n",
    "        mtlbox_2 = Box(children=mtlitems_2, layout=mtl_layout)\n",
    "        mtlbox_3 = Box(children=mtlitems_3, layout=mtl_layout2)\n",
    "\n",
    "\n",
    "        display(VBox([(HBox([mtlbox_1, mtlbox_2])),(HBox([mtlbox_3]))]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
